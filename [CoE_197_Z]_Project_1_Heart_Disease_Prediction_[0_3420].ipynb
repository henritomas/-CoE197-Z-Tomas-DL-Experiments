{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[CoE 197-Z] Project 1 - Heart Disease Prediction - [0.3420].ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "HWq-r0Hs97bb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#[COE 197-Z] Project 1: Heart Disease Prediction Model\n",
        "\n",
        "**Changelog**\n",
        "\n",
        "\n",
        "*   [3:44 AM, 3-13-19] Train: 86.67%, Test: 84.44%, Drivendata Score: 0.3420, Leaderboard Rank :103\n",
        "*   note: adding batchnorm + dropout increases accuracy but makes log loss error higher because model makes less confident predictions. This tanks the ranking even though you have a more accurate model. \n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "goqAZnNEw-dr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Preprocess Data using Pandas**\n",
        "\n",
        "Note: Since I have zero background on preprocessing tabular data, the following was used as the main reference for this section: \n",
        "[Preprocessing Tabular Data](https://github.com/AnneDeGraaf/DrivenData_WarmUp_HeartDisease/blob/master/data_processing.py?fbclid=IwAR3Spxx1yyaRRpyO2yPeajdlv3SgcWuy-9ZwPLW5SPTWNIpzr0TFtph5h38)\n",
        "Credits to  .[AnneDeGraaf](https://github.com/AnneDeGraaf/)"
      ]
    },
    {
      "metadata": {
        "id": "lAXLBd829MUz",
        "colab_type": "code",
        "outputId": "9f772f68-e263-4696-d7bd-d49053593a43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Dropout, Input, BatchNormalization\n",
        "from keras.regularizers import l2\n",
        "from keras.utils import to_categorical\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_url = 'https://raw.githubusercontent.com/henritomas/CoE197-Z-Tomas-DL-Experiments/master/train_values.csv'\n",
        "test_url = 'https://raw.githubusercontent.com/henritomas/CoE197-Z-Tomas-DL-Experiments/master/test_values.csv'\n",
        "rawTrain = pd.read_csv(train_url)\n",
        "rawTest = pd.read_csv(test_url)\n",
        "\n",
        "# change categorical data into one-hot:\n",
        "trainSlope_oneHot = pd.get_dummies(rawTrain['slope_of_peak_exercise_st_segment'], prefix='slope')\n",
        "trainThal_oneHot = pd.get_dummies(rawTrain['thal'])\n",
        "trainChestPain_oneHot = pd.get_dummies(rawTrain['chest_pain_type'], prefix='chestPain')\n",
        "trainResting_oneHot = pd.get_dummies(rawTrain['resting_ekg_results'], prefix='restingEkg')\n",
        "testSlope_oneHot = pd.get_dummies(rawTest['slope_of_peak_exercise_st_segment'], prefix='slope')\n",
        "testThal_oneHot = pd.get_dummies(rawTest['thal'])\n",
        "testChestPain_oneHot = pd.get_dummies(rawTest['chest_pain_type'], prefix='chestPain')\n",
        "testResting_oneHot = pd.get_dummies(rawTest['resting_ekg_results'], prefix='restingEkg')\n",
        "\n",
        "# replace categorical columns by one-hot\n",
        "rawTrain.drop(['slope_of_peak_exercise_st_segment','thal','chest_pain_type','resting_ekg_results'], axis=1, inplace=True)\n",
        "rawTrain = rawTrain.join([trainSlope_oneHot, trainThal_oneHot, trainChestPain_oneHot, trainResting_oneHot])\n",
        "rawTest.drop(['slope_of_peak_exercise_st_segment','thal','chest_pain_type','resting_ekg_results'], axis=1, inplace=True)\n",
        "rawTest = rawTest.join([testSlope_oneHot, testThal_oneHot, testChestPain_oneHot, testResting_oneHot])\n",
        "\n",
        "# check for NaN's in dataset\n",
        "print(rawTrain.isnull().values.any())\n",
        "print(rawTest.isnull().values.any())\n",
        "\n",
        "# apply normalization to numerical data\n",
        "numCols = ['resting_blood_pressure', 'serum_cholesterol_mg_per_dl', 'oldpeak_eq_st_depression', 'age', 'max_heart_rate_achieved']\n",
        "for col in numCols:\n",
        "\trawTest[col] = (rawTest[col] - rawTrain[col].mean()) / rawTrain[col].std()\n",
        "\trawTrain[col] = (rawTrain[col] - rawTrain[col].mean()) / rawTrain[col].std()\n",
        "\tprint(rawTrain[col].mean(), rawTrain[col].std()) # should be 0 and 1\n",
        "\n",
        "# Storing processed data into new file\n",
        "rawTrain.to_csv('../train_values_normalized.csv')\n",
        "rawTest.to_csv('../test_values_normalized.csv')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n",
            "False\n",
            "4.354541418807558e-16 1.0\n",
            "4.502571155424246e-17 1.0\n",
            "6.1679056923619804e-18 0.9999999999999992\n",
            "1.0986582014519779e-16 0.9999999999999994\n",
            "5.896517841898053e-16 1.0000000000000004\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Yg_qi2KD29-V",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Deep Learning Model Proper**"
      ]
    },
    {
      "metadata": {
        "id": "vzCmGMGj29Vg",
        "colab_type": "code",
        "outputId": "bfaed80a-4397-4ebe-da03-1d0cc2cbbf8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17874
        }
      },
      "cell_type": "code",
      "source": [
        "#Load pre-processed/ normalized data, mark column 0 as the index (patiend id)\n",
        "train_labels_url = 'https://raw.githubusercontent.com/henritomas/CoE197-Z-Tomas-DL-Experiments/master/train_labels.csv'\n",
        "x_train = pd.read_csv('../train_values_normalized.csv', index_col=0)\n",
        "y_train = pd.read_csv(train_labels_url, index_col=0)\n",
        "\n",
        "#Reshape/Format data\n",
        "num_labels = len(np.unique(y_train))\n",
        "y_train = to_categorical(y_train)\n",
        "x_train = x_train.drop('patient_id',1) #Drops/deletes patient_id column\n",
        "\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(x_train, \n",
        "                                                      y_train, \n",
        "                                                      test_size=0.5)\n",
        "np.random.seed(1)\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(1)\n",
        "\n",
        "#Network Parameters\n",
        "input_dim = (x_train.shape[1],) #required to be a tuple\n",
        "batch_size = 32\n",
        "epochs = 500\n",
        "\n",
        "kreg = l2(0.0001)\n",
        "\n",
        "#Build Model\n",
        "inputs = Input(shape=input_dim)\n",
        "y = Dense(15,\n",
        "          input_dim=input_dim,\n",
        "          activation='relu',\n",
        "          kernel_regularizer=kreg)(inputs)\n",
        "y = Dense(15,\n",
        "          input_dim=input_dim,\n",
        "          activation='relu',\n",
        "          kernel_regularizer=kreg)(y)\n",
        "outputs = Dense(num_labels, activation='softmax',\n",
        "               kernel_regularizer=kreg)(y)\n",
        "opt = Adam(lr=0.0001, \n",
        "           beta_1=0.9, \n",
        "           beta_2=0.999, \n",
        "           epsilon=1e-7, \n",
        "           decay=0.0, \n",
        "           amsgrad=False)\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#Train Model\n",
        "history = model.fit(x_train, y_train,\n",
        "                    validation_data=(x_valid, y_valid),\n",
        "                    epochs=epochs,\n",
        "                    batch_size=batch_size)\n",
        "\"\"\"\n",
        "Accuracy is printed out, but for loss='***_crossentropy' log loss is\n",
        "also printed out by default (loss/val_loss)\n",
        "\"\"\"\n",
        "\n",
        "#Final Accuracy on Test Data Set\n",
        "scores = model.evaluate(x_valid, y_valid, batch_size=batch_size)\n",
        "print(\"\\nTest Accuracy: %.2f%%\" % (100.0 * scores[1])) \n",
        "\n",
        "#Plot validation vs training accuracy\n",
        "print(history.history.keys())\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "#Plot validation vs training loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(180, 22)\n",
            "(180, 2)\n",
            "Train on 90 samples, validate on 90 samples\n",
            "Epoch 1/500\n",
            "90/90 [==============================] - 13s 149ms/step - loss: 0.7102 - acc: 0.5000 - val_loss: 0.6909 - val_acc: 0.5667\n",
            "Epoch 2/500\n",
            "90/90 [==============================] - 0s 390us/step - loss: 0.7083 - acc: 0.5111 - val_loss: 0.6899 - val_acc: 0.5778\n",
            "Epoch 3/500\n",
            "90/90 [==============================] - 0s 329us/step - loss: 0.7065 - acc: 0.5111 - val_loss: 0.6889 - val_acc: 0.5778\n",
            "Epoch 4/500\n",
            "90/90 [==============================] - 0s 334us/step - loss: 0.7050 - acc: 0.5222 - val_loss: 0.6879 - val_acc: 0.5778\n",
            "Epoch 5/500\n",
            "90/90 [==============================] - 0s 323us/step - loss: 0.7032 - acc: 0.5222 - val_loss: 0.6869 - val_acc: 0.5778\n",
            "Epoch 6/500\n",
            "90/90 [==============================] - 0s 333us/step - loss: 0.7016 - acc: 0.5333 - val_loss: 0.6859 - val_acc: 0.5778\n",
            "Epoch 7/500\n",
            "90/90 [==============================] - 0s 454us/step - loss: 0.6998 - acc: 0.5444 - val_loss: 0.6849 - val_acc: 0.5889\n",
            "Epoch 8/500\n",
            "90/90 [==============================] - 0s 392us/step - loss: 0.6982 - acc: 0.5556 - val_loss: 0.6839 - val_acc: 0.5889\n",
            "Epoch 9/500\n",
            "90/90 [==============================] - 0s 326us/step - loss: 0.6964 - acc: 0.5444 - val_loss: 0.6829 - val_acc: 0.6111\n",
            "Epoch 10/500\n",
            "90/90 [==============================] - 0s 313us/step - loss: 0.6948 - acc: 0.5444 - val_loss: 0.6819 - val_acc: 0.6111\n",
            "Epoch 11/500\n",
            "90/90 [==============================] - 0s 325us/step - loss: 0.6932 - acc: 0.5444 - val_loss: 0.6809 - val_acc: 0.6000\n",
            "Epoch 12/500\n",
            "90/90 [==============================] - 0s 318us/step - loss: 0.6917 - acc: 0.5444 - val_loss: 0.6798 - val_acc: 0.6000\n",
            "Epoch 13/500\n",
            "90/90 [==============================] - 0s 385us/step - loss: 0.6900 - acc: 0.5444 - val_loss: 0.6788 - val_acc: 0.6000\n",
            "Epoch 14/500\n",
            "90/90 [==============================] - 0s 357us/step - loss: 0.6883 - acc: 0.5444 - val_loss: 0.6778 - val_acc: 0.6000\n",
            "Epoch 15/500\n",
            "90/90 [==============================] - 0s 339us/step - loss: 0.6867 - acc: 0.5444 - val_loss: 0.6767 - val_acc: 0.6000\n",
            "Epoch 16/500\n",
            "90/90 [==============================] - 0s 356us/step - loss: 0.6851 - acc: 0.5556 - val_loss: 0.6757 - val_acc: 0.6000\n",
            "Epoch 17/500\n",
            "90/90 [==============================] - 0s 383us/step - loss: 0.6833 - acc: 0.5778 - val_loss: 0.6747 - val_acc: 0.6000\n",
            "Epoch 18/500\n",
            "90/90 [==============================] - 0s 372us/step - loss: 0.6818 - acc: 0.5778 - val_loss: 0.6737 - val_acc: 0.6111\n",
            "Epoch 19/500\n",
            "90/90 [==============================] - 0s 374us/step - loss: 0.6802 - acc: 0.5889 - val_loss: 0.6727 - val_acc: 0.6222\n",
            "Epoch 20/500\n",
            "90/90 [==============================] - 0s 361us/step - loss: 0.6785 - acc: 0.6000 - val_loss: 0.6717 - val_acc: 0.6222\n",
            "Epoch 21/500\n",
            "90/90 [==============================] - 0s 329us/step - loss: 0.6769 - acc: 0.6111 - val_loss: 0.6707 - val_acc: 0.6222\n",
            "Epoch 22/500\n",
            "90/90 [==============================] - 0s 383us/step - loss: 0.6755 - acc: 0.6111 - val_loss: 0.6698 - val_acc: 0.6222\n",
            "Epoch 23/500\n",
            "90/90 [==============================] - 0s 372us/step - loss: 0.6738 - acc: 0.6222 - val_loss: 0.6688 - val_acc: 0.6222\n",
            "Epoch 24/500\n",
            "90/90 [==============================] - 0s 295us/step - loss: 0.6722 - acc: 0.6222 - val_loss: 0.6678 - val_acc: 0.6222\n",
            "Epoch 25/500\n",
            "90/90 [==============================] - 0s 362us/step - loss: 0.6709 - acc: 0.6222 - val_loss: 0.6669 - val_acc: 0.6222\n",
            "Epoch 26/500\n",
            "90/90 [==============================] - 0s 354us/step - loss: 0.6693 - acc: 0.6222 - val_loss: 0.6659 - val_acc: 0.6222\n",
            "Epoch 27/500\n",
            "90/90 [==============================] - 0s 340us/step - loss: 0.6678 - acc: 0.6333 - val_loss: 0.6650 - val_acc: 0.6333\n",
            "Epoch 28/500\n",
            "90/90 [==============================] - 0s 369us/step - loss: 0.6664 - acc: 0.6333 - val_loss: 0.6640 - val_acc: 0.6333\n",
            "Epoch 29/500\n",
            "90/90 [==============================] - 0s 357us/step - loss: 0.6647 - acc: 0.6333 - val_loss: 0.6630 - val_acc: 0.6333\n",
            "Epoch 30/500\n",
            "90/90 [==============================] - 0s 371us/step - loss: 0.6634 - acc: 0.6444 - val_loss: 0.6621 - val_acc: 0.6333\n",
            "Epoch 31/500\n",
            "90/90 [==============================] - 0s 356us/step - loss: 0.6618 - acc: 0.6444 - val_loss: 0.6612 - val_acc: 0.6333\n",
            "Epoch 32/500\n",
            "90/90 [==============================] - 0s 353us/step - loss: 0.6605 - acc: 0.6444 - val_loss: 0.6602 - val_acc: 0.6444\n",
            "Epoch 33/500\n",
            "90/90 [==============================] - 0s 307us/step - loss: 0.6590 - acc: 0.6444 - val_loss: 0.6593 - val_acc: 0.6444\n",
            "Epoch 34/500\n",
            "90/90 [==============================] - 0s 325us/step - loss: 0.6576 - acc: 0.6556 - val_loss: 0.6583 - val_acc: 0.6444\n",
            "Epoch 35/500\n",
            "90/90 [==============================] - 0s 369us/step - loss: 0.6562 - acc: 0.6556 - val_loss: 0.6574 - val_acc: 0.6444\n",
            "Epoch 36/500\n",
            "90/90 [==============================] - 0s 346us/step - loss: 0.6549 - acc: 0.6778 - val_loss: 0.6565 - val_acc: 0.6444\n",
            "Epoch 37/500\n",
            "90/90 [==============================] - 0s 513us/step - loss: 0.6535 - acc: 0.6778 - val_loss: 0.6555 - val_acc: 0.6444\n",
            "Epoch 38/500\n",
            "90/90 [==============================] - 0s 346us/step - loss: 0.6521 - acc: 0.6778 - val_loss: 0.6546 - val_acc: 0.6444\n",
            "Epoch 39/500\n",
            "90/90 [==============================] - 0s 335us/step - loss: 0.6508 - acc: 0.6667 - val_loss: 0.6537 - val_acc: 0.6444\n",
            "Epoch 40/500\n",
            "90/90 [==============================] - 0s 337us/step - loss: 0.6494 - acc: 0.6667 - val_loss: 0.6528 - val_acc: 0.6444\n",
            "Epoch 41/500\n",
            "90/90 [==============================] - 0s 352us/step - loss: 0.6481 - acc: 0.6667 - val_loss: 0.6518 - val_acc: 0.6444\n",
            "Epoch 42/500\n",
            "90/90 [==============================] - 0s 316us/step - loss: 0.6468 - acc: 0.6667 - val_loss: 0.6509 - val_acc: 0.6444\n",
            "Epoch 43/500\n",
            "90/90 [==============================] - 0s 330us/step - loss: 0.6455 - acc: 0.6667 - val_loss: 0.6500 - val_acc: 0.6444\n",
            "Epoch 44/500\n",
            "90/90 [==============================] - 0s 364us/step - loss: 0.6442 - acc: 0.6667 - val_loss: 0.6490 - val_acc: 0.6444\n",
            "Epoch 45/500\n",
            "90/90 [==============================] - 0s 376us/step - loss: 0.6429 - acc: 0.6556 - val_loss: 0.6481 - val_acc: 0.6444\n",
            "Epoch 46/500\n",
            "90/90 [==============================] - 0s 374us/step - loss: 0.6417 - acc: 0.6556 - val_loss: 0.6472 - val_acc: 0.6444\n",
            "Epoch 47/500\n",
            "90/90 [==============================] - 0s 373us/step - loss: 0.6404 - acc: 0.6556 - val_loss: 0.6463 - val_acc: 0.6444\n",
            "Epoch 48/500\n",
            "90/90 [==============================] - 0s 326us/step - loss: 0.6390 - acc: 0.6556 - val_loss: 0.6453 - val_acc: 0.6556\n",
            "Epoch 49/500\n",
            "90/90 [==============================] - 0s 309us/step - loss: 0.6377 - acc: 0.6556 - val_loss: 0.6444 - val_acc: 0.6556\n",
            "Epoch 50/500\n",
            "90/90 [==============================] - 0s 356us/step - loss: 0.6365 - acc: 0.6556 - val_loss: 0.6435 - val_acc: 0.6556\n",
            "Epoch 51/500\n",
            "90/90 [==============================] - 0s 378us/step - loss: 0.6351 - acc: 0.6556 - val_loss: 0.6425 - val_acc: 0.6556\n",
            "Epoch 52/500\n",
            "90/90 [==============================] - 0s 375us/step - loss: 0.6337 - acc: 0.6556 - val_loss: 0.6416 - val_acc: 0.6556\n",
            "Epoch 53/500\n",
            "90/90 [==============================] - 0s 341us/step - loss: 0.6326 - acc: 0.6556 - val_loss: 0.6407 - val_acc: 0.6556\n",
            "Epoch 54/500\n",
            "90/90 [==============================] - 0s 360us/step - loss: 0.6312 - acc: 0.6556 - val_loss: 0.6397 - val_acc: 0.6556\n",
            "Epoch 55/500\n",
            "90/90 [==============================] - 0s 333us/step - loss: 0.6299 - acc: 0.6556 - val_loss: 0.6388 - val_acc: 0.6556\n",
            "Epoch 56/500\n",
            "90/90 [==============================] - 0s 330us/step - loss: 0.6287 - acc: 0.6556 - val_loss: 0.6379 - val_acc: 0.6556\n",
            "Epoch 57/500\n",
            "90/90 [==============================] - 0s 350us/step - loss: 0.6275 - acc: 0.6556 - val_loss: 0.6369 - val_acc: 0.6556\n",
            "Epoch 58/500\n",
            "90/90 [==============================] - 0s 379us/step - loss: 0.6262 - acc: 0.6556 - val_loss: 0.6360 - val_acc: 0.6556\n",
            "Epoch 59/500\n",
            "90/90 [==============================] - 0s 345us/step - loss: 0.6250 - acc: 0.6556 - val_loss: 0.6351 - val_acc: 0.6556\n",
            "Epoch 60/500\n",
            "90/90 [==============================] - 0s 356us/step - loss: 0.6237 - acc: 0.6556 - val_loss: 0.6342 - val_acc: 0.6556\n",
            "Epoch 61/500\n",
            "90/90 [==============================] - 0s 370us/step - loss: 0.6225 - acc: 0.6556 - val_loss: 0.6332 - val_acc: 0.6556\n",
            "Epoch 62/500\n",
            "90/90 [==============================] - 0s 342us/step - loss: 0.6213 - acc: 0.6556 - val_loss: 0.6323 - val_acc: 0.6556\n",
            "Epoch 63/500\n",
            "90/90 [==============================] - 0s 358us/step - loss: 0.6201 - acc: 0.6667 - val_loss: 0.6314 - val_acc: 0.6556\n",
            "Epoch 64/500\n",
            "90/90 [==============================] - 0s 343us/step - loss: 0.6188 - acc: 0.6667 - val_loss: 0.6305 - val_acc: 0.6667\n",
            "Epoch 65/500\n",
            "90/90 [==============================] - 0s 354us/step - loss: 0.6177 - acc: 0.6667 - val_loss: 0.6296 - val_acc: 0.6667\n",
            "Epoch 66/500\n",
            "90/90 [==============================] - 0s 354us/step - loss: 0.6164 - acc: 0.6667 - val_loss: 0.6286 - val_acc: 0.6667\n",
            "Epoch 67/500\n",
            "90/90 [==============================] - 0s 453us/step - loss: 0.6153 - acc: 0.6778 - val_loss: 0.6277 - val_acc: 0.6778\n",
            "Epoch 68/500\n",
            "90/90 [==============================] - 0s 417us/step - loss: 0.6141 - acc: 0.6778 - val_loss: 0.6268 - val_acc: 0.6778\n",
            "Epoch 69/500\n",
            "90/90 [==============================] - 0s 344us/step - loss: 0.6128 - acc: 0.6778 - val_loss: 0.6259 - val_acc: 0.6889\n",
            "Epoch 70/500\n",
            "90/90 [==============================] - 0s 370us/step - loss: 0.6115 - acc: 0.6778 - val_loss: 0.6250 - val_acc: 0.6889\n",
            "Epoch 71/500\n",
            "90/90 [==============================] - 0s 325us/step - loss: 0.6104 - acc: 0.6778 - val_loss: 0.6241 - val_acc: 0.6889\n",
            "Epoch 72/500\n",
            "90/90 [==============================] - 0s 325us/step - loss: 0.6092 - acc: 0.6778 - val_loss: 0.6231 - val_acc: 0.6889\n",
            "Epoch 73/500\n",
            "90/90 [==============================] - 0s 313us/step - loss: 0.6080 - acc: 0.6778 - val_loss: 0.6222 - val_acc: 0.6889\n",
            "Epoch 74/500\n",
            "90/90 [==============================] - 0s 394us/step - loss: 0.6068 - acc: 0.6778 - val_loss: 0.6213 - val_acc: 0.6889\n",
            "Epoch 75/500\n",
            "90/90 [==============================] - 0s 373us/step - loss: 0.6057 - acc: 0.6889 - val_loss: 0.6203 - val_acc: 0.6889\n",
            "Epoch 76/500\n",
            "90/90 [==============================] - 0s 354us/step - loss: 0.6045 - acc: 0.6889 - val_loss: 0.6193 - val_acc: 0.6889\n",
            "Epoch 77/500\n",
            "90/90 [==============================] - 0s 393us/step - loss: 0.6033 - acc: 0.6889 - val_loss: 0.6184 - val_acc: 0.6889\n",
            "Epoch 78/500\n",
            "90/90 [==============================] - 0s 322us/step - loss: 0.6021 - acc: 0.6889 - val_loss: 0.6175 - val_acc: 0.7000\n",
            "Epoch 79/500\n",
            "90/90 [==============================] - 0s 335us/step - loss: 0.6009 - acc: 0.7000 - val_loss: 0.6166 - val_acc: 0.7000\n",
            "Epoch 80/500\n",
            "90/90 [==============================] - 0s 389us/step - loss: 0.5998 - acc: 0.7000 - val_loss: 0.6156 - val_acc: 0.7000\n",
            "Epoch 81/500\n",
            "90/90 [==============================] - 0s 426us/step - loss: 0.5987 - acc: 0.7000 - val_loss: 0.6147 - val_acc: 0.7000\n",
            "Epoch 82/500\n",
            "90/90 [==============================] - 0s 368us/step - loss: 0.5976 - acc: 0.6889 - val_loss: 0.6137 - val_acc: 0.7000\n",
            "Epoch 83/500\n",
            "90/90 [==============================] - 0s 368us/step - loss: 0.5965 - acc: 0.6778 - val_loss: 0.6129 - val_acc: 0.7000\n",
            "Epoch 84/500\n",
            "90/90 [==============================] - 0s 352us/step - loss: 0.5953 - acc: 0.6778 - val_loss: 0.6119 - val_acc: 0.7000\n",
            "Epoch 85/500\n",
            "90/90 [==============================] - 0s 339us/step - loss: 0.5942 - acc: 0.6889 - val_loss: 0.6110 - val_acc: 0.7000\n",
            "Epoch 86/500\n",
            "90/90 [==============================] - 0s 372us/step - loss: 0.5931 - acc: 0.7000 - val_loss: 0.6101 - val_acc: 0.7000\n",
            "Epoch 87/500\n",
            "90/90 [==============================] - 0s 382us/step - loss: 0.5921 - acc: 0.7111 - val_loss: 0.6092 - val_acc: 0.7000\n",
            "Epoch 88/500\n",
            "90/90 [==============================] - 0s 343us/step - loss: 0.5910 - acc: 0.7111 - val_loss: 0.6083 - val_acc: 0.7000\n",
            "Epoch 89/500\n",
            "90/90 [==============================] - 0s 403us/step - loss: 0.5899 - acc: 0.7111 - val_loss: 0.6074 - val_acc: 0.7000\n",
            "Epoch 90/500\n",
            "90/90 [==============================] - 0s 330us/step - loss: 0.5889 - acc: 0.7111 - val_loss: 0.6065 - val_acc: 0.7000\n",
            "Epoch 91/500\n",
            "90/90 [==============================] - 0s 372us/step - loss: 0.5878 - acc: 0.7111 - val_loss: 0.6056 - val_acc: 0.7111\n",
            "Epoch 92/500\n",
            "90/90 [==============================] - 0s 421us/step - loss: 0.5868 - acc: 0.7111 - val_loss: 0.6048 - val_acc: 0.7111\n",
            "Epoch 93/500\n",
            "90/90 [==============================] - 0s 318us/step - loss: 0.5857 - acc: 0.7111 - val_loss: 0.6039 - val_acc: 0.7111\n",
            "Epoch 94/500\n",
            "90/90 [==============================] - 0s 364us/step - loss: 0.5848 - acc: 0.7333 - val_loss: 0.6030 - val_acc: 0.7111\n",
            "Epoch 95/500\n",
            "90/90 [==============================] - 0s 361us/step - loss: 0.5837 - acc: 0.7333 - val_loss: 0.6021 - val_acc: 0.7111\n",
            "Epoch 96/500\n",
            "90/90 [==============================] - 0s 318us/step - loss: 0.5827 - acc: 0.7333 - val_loss: 0.6012 - val_acc: 0.7222\n",
            "Epoch 97/500\n",
            "90/90 [==============================] - 0s 463us/step - loss: 0.5817 - acc: 0.7444 - val_loss: 0.6003 - val_acc: 0.7222\n",
            "Epoch 98/500\n",
            "90/90 [==============================] - 0s 460us/step - loss: 0.5806 - acc: 0.7444 - val_loss: 0.5994 - val_acc: 0.7222\n",
            "Epoch 99/500\n",
            "90/90 [==============================] - 0s 360us/step - loss: 0.5797 - acc: 0.7444 - val_loss: 0.5985 - val_acc: 0.7222\n",
            "Epoch 100/500\n",
            "90/90 [==============================] - 0s 385us/step - loss: 0.5787 - acc: 0.7444 - val_loss: 0.5975 - val_acc: 0.7222\n",
            "Epoch 101/500\n",
            "90/90 [==============================] - 0s 365us/step - loss: 0.5777 - acc: 0.7444 - val_loss: 0.5966 - val_acc: 0.7222\n",
            "Epoch 102/500\n",
            "90/90 [==============================] - 0s 373us/step - loss: 0.5766 - acc: 0.7444 - val_loss: 0.5957 - val_acc: 0.7222\n",
            "Epoch 103/500\n",
            "90/90 [==============================] - 0s 348us/step - loss: 0.5757 - acc: 0.7333 - val_loss: 0.5948 - val_acc: 0.7222\n",
            "Epoch 104/500\n",
            "90/90 [==============================] - 0s 316us/step - loss: 0.5746 - acc: 0.7444 - val_loss: 0.5938 - val_acc: 0.7222\n",
            "Epoch 105/500\n",
            "90/90 [==============================] - 0s 348us/step - loss: 0.5737 - acc: 0.7444 - val_loss: 0.5929 - val_acc: 0.7222\n",
            "Epoch 106/500\n",
            "90/90 [==============================] - 0s 340us/step - loss: 0.5727 - acc: 0.7444 - val_loss: 0.5919 - val_acc: 0.7222\n",
            "Epoch 107/500\n",
            "90/90 [==============================] - 0s 354us/step - loss: 0.5717 - acc: 0.7444 - val_loss: 0.5910 - val_acc: 0.7222\n",
            "Epoch 108/500\n",
            "90/90 [==============================] - 0s 381us/step - loss: 0.5708 - acc: 0.7444 - val_loss: 0.5900 - val_acc: 0.7222\n",
            "Epoch 109/500\n",
            "90/90 [==============================] - 0s 327us/step - loss: 0.5698 - acc: 0.7444 - val_loss: 0.5891 - val_acc: 0.7222\n",
            "Epoch 110/500\n",
            "90/90 [==============================] - 0s 341us/step - loss: 0.5688 - acc: 0.7444 - val_loss: 0.5882 - val_acc: 0.7222\n",
            "Epoch 111/500\n",
            "90/90 [==============================] - 0s 323us/step - loss: 0.5677 - acc: 0.7444 - val_loss: 0.5872 - val_acc: 0.7222\n",
            "Epoch 112/500\n",
            "90/90 [==============================] - 0s 343us/step - loss: 0.5668 - acc: 0.7444 - val_loss: 0.5863 - val_acc: 0.7222\n",
            "Epoch 113/500\n",
            "90/90 [==============================] - 0s 359us/step - loss: 0.5657 - acc: 0.7444 - val_loss: 0.5853 - val_acc: 0.7222\n",
            "Epoch 114/500\n",
            "90/90 [==============================] - 0s 380us/step - loss: 0.5648 - acc: 0.7444 - val_loss: 0.5843 - val_acc: 0.7222\n",
            "Epoch 115/500\n",
            "90/90 [==============================] - 0s 359us/step - loss: 0.5638 - acc: 0.7444 - val_loss: 0.5834 - val_acc: 0.7333\n",
            "Epoch 116/500\n",
            "90/90 [==============================] - 0s 320us/step - loss: 0.5627 - acc: 0.7444 - val_loss: 0.5824 - val_acc: 0.7333\n",
            "Epoch 117/500\n",
            "90/90 [==============================] - 0s 354us/step - loss: 0.5618 - acc: 0.7556 - val_loss: 0.5814 - val_acc: 0.7333\n",
            "Epoch 118/500\n",
            "90/90 [==============================] - 0s 350us/step - loss: 0.5607 - acc: 0.7556 - val_loss: 0.5805 - val_acc: 0.7333\n",
            "Epoch 119/500\n",
            "90/90 [==============================] - 0s 399us/step - loss: 0.5598 - acc: 0.7556 - val_loss: 0.5795 - val_acc: 0.7333\n",
            "Epoch 120/500\n",
            "90/90 [==============================] - 0s 387us/step - loss: 0.5588 - acc: 0.7556 - val_loss: 0.5786 - val_acc: 0.7333\n",
            "Epoch 121/500\n",
            "90/90 [==============================] - 0s 342us/step - loss: 0.5578 - acc: 0.7556 - val_loss: 0.5776 - val_acc: 0.7333\n",
            "Epoch 122/500\n",
            "90/90 [==============================] - 0s 342us/step - loss: 0.5568 - acc: 0.7556 - val_loss: 0.5767 - val_acc: 0.7444\n",
            "Epoch 123/500\n",
            "90/90 [==============================] - 0s 300us/step - loss: 0.5559 - acc: 0.7556 - val_loss: 0.5757 - val_acc: 0.7444\n",
            "Epoch 124/500\n",
            "90/90 [==============================] - 0s 395us/step - loss: 0.5549 - acc: 0.7556 - val_loss: 0.5747 - val_acc: 0.7556\n",
            "Epoch 125/500\n",
            "90/90 [==============================] - 0s 386us/step - loss: 0.5539 - acc: 0.7667 - val_loss: 0.5738 - val_acc: 0.7556\n",
            "Epoch 126/500\n",
            "90/90 [==============================] - 0s 372us/step - loss: 0.5529 - acc: 0.7667 - val_loss: 0.5728 - val_acc: 0.7556\n",
            "Epoch 127/500\n",
            "90/90 [==============================] - 0s 409us/step - loss: 0.5519 - acc: 0.7667 - val_loss: 0.5718 - val_acc: 0.7556\n",
            "Epoch 128/500\n",
            "90/90 [==============================] - 0s 440us/step - loss: 0.5509 - acc: 0.7667 - val_loss: 0.5708 - val_acc: 0.7556\n",
            "Epoch 129/500\n",
            "90/90 [==============================] - 0s 347us/step - loss: 0.5499 - acc: 0.7667 - val_loss: 0.5699 - val_acc: 0.7556\n",
            "Epoch 130/500\n",
            "90/90 [==============================] - 0s 331us/step - loss: 0.5489 - acc: 0.7667 - val_loss: 0.5689 - val_acc: 0.7556\n",
            "Epoch 131/500\n",
            "90/90 [==============================] - 0s 317us/step - loss: 0.5479 - acc: 0.7667 - val_loss: 0.5679 - val_acc: 0.7556\n",
            "Epoch 132/500\n",
            "90/90 [==============================] - 0s 346us/step - loss: 0.5469 - acc: 0.7667 - val_loss: 0.5669 - val_acc: 0.7556\n",
            "Epoch 133/500\n",
            "90/90 [==============================] - 0s 330us/step - loss: 0.5458 - acc: 0.7667 - val_loss: 0.5660 - val_acc: 0.7556\n",
            "Epoch 134/500\n",
            "90/90 [==============================] - 0s 359us/step - loss: 0.5449 - acc: 0.7667 - val_loss: 0.5650 - val_acc: 0.7556\n",
            "Epoch 135/500\n",
            "90/90 [==============================] - 0s 344us/step - loss: 0.5439 - acc: 0.7667 - val_loss: 0.5640 - val_acc: 0.7556\n",
            "Epoch 136/500\n",
            "90/90 [==============================] - 0s 364us/step - loss: 0.5429 - acc: 0.7667 - val_loss: 0.5630 - val_acc: 0.7556\n",
            "Epoch 137/500\n",
            "90/90 [==============================] - 0s 365us/step - loss: 0.5418 - acc: 0.7667 - val_loss: 0.5621 - val_acc: 0.7556\n",
            "Epoch 138/500\n",
            "90/90 [==============================] - 0s 425us/step - loss: 0.5408 - acc: 0.7778 - val_loss: 0.5611 - val_acc: 0.7667\n",
            "Epoch 139/500\n",
            "90/90 [==============================] - 0s 338us/step - loss: 0.5399 - acc: 0.7778 - val_loss: 0.5602 - val_acc: 0.7667\n",
            "Epoch 140/500\n",
            "90/90 [==============================] - 0s 363us/step - loss: 0.5389 - acc: 0.7778 - val_loss: 0.5592 - val_acc: 0.7667\n",
            "Epoch 141/500\n",
            "90/90 [==============================] - 0s 331us/step - loss: 0.5379 - acc: 0.7778 - val_loss: 0.5582 - val_acc: 0.7778\n",
            "Epoch 142/500\n",
            "90/90 [==============================] - 0s 357us/step - loss: 0.5369 - acc: 0.7778 - val_loss: 0.5572 - val_acc: 0.7778\n",
            "Epoch 143/500\n",
            "90/90 [==============================] - 0s 357us/step - loss: 0.5358 - acc: 0.7778 - val_loss: 0.5563 - val_acc: 0.7778\n",
            "Epoch 144/500\n",
            "90/90 [==============================] - 0s 375us/step - loss: 0.5348 - acc: 0.7778 - val_loss: 0.5553 - val_acc: 0.7778\n",
            "Epoch 145/500\n",
            "90/90 [==============================] - 0s 379us/step - loss: 0.5338 - acc: 0.7889 - val_loss: 0.5544 - val_acc: 0.7778\n",
            "Epoch 146/500\n",
            "90/90 [==============================] - 0s 365us/step - loss: 0.5329 - acc: 0.7889 - val_loss: 0.5534 - val_acc: 0.7778\n",
            "Epoch 147/500\n",
            "90/90 [==============================] - 0s 373us/step - loss: 0.5319 - acc: 0.7889 - val_loss: 0.5524 - val_acc: 0.7778\n",
            "Epoch 148/500\n",
            "90/90 [==============================] - 0s 385us/step - loss: 0.5308 - acc: 0.7889 - val_loss: 0.5515 - val_acc: 0.7889\n",
            "Epoch 149/500\n",
            "90/90 [==============================] - 0s 357us/step - loss: 0.5299 - acc: 0.7889 - val_loss: 0.5505 - val_acc: 0.7889\n",
            "Epoch 150/500\n",
            "90/90 [==============================] - 0s 390us/step - loss: 0.5289 - acc: 0.7889 - val_loss: 0.5495 - val_acc: 0.7889\n",
            "Epoch 151/500\n",
            "90/90 [==============================] - 0s 364us/step - loss: 0.5278 - acc: 0.7889 - val_loss: 0.5486 - val_acc: 0.7889\n",
            "Epoch 152/500\n",
            "90/90 [==============================] - 0s 394us/step - loss: 0.5269 - acc: 0.7889 - val_loss: 0.5476 - val_acc: 0.7889\n",
            "Epoch 153/500\n",
            "90/90 [==============================] - 0s 378us/step - loss: 0.5259 - acc: 0.7889 - val_loss: 0.5467 - val_acc: 0.7889\n",
            "Epoch 154/500\n",
            "90/90 [==============================] - 0s 387us/step - loss: 0.5249 - acc: 0.7889 - val_loss: 0.5458 - val_acc: 0.7889\n",
            "Epoch 155/500\n",
            "90/90 [==============================] - 0s 384us/step - loss: 0.5240 - acc: 0.7889 - val_loss: 0.5448 - val_acc: 0.7889\n",
            "Epoch 156/500\n",
            "90/90 [==============================] - 0s 385us/step - loss: 0.5229 - acc: 0.7889 - val_loss: 0.5439 - val_acc: 0.7889\n",
            "Epoch 157/500\n",
            "90/90 [==============================] - 0s 540us/step - loss: 0.5220 - acc: 0.8000 - val_loss: 0.5429 - val_acc: 0.7889\n",
            "Epoch 158/500\n",
            "90/90 [==============================] - 0s 434us/step - loss: 0.5211 - acc: 0.8000 - val_loss: 0.5420 - val_acc: 0.7889\n",
            "Epoch 159/500\n",
            "90/90 [==============================] - 0s 421us/step - loss: 0.5201 - acc: 0.8000 - val_loss: 0.5410 - val_acc: 0.7889\n",
            "Epoch 160/500\n",
            "90/90 [==============================] - 0s 381us/step - loss: 0.5192 - acc: 0.8000 - val_loss: 0.5401 - val_acc: 0.7889\n",
            "Epoch 161/500\n",
            "90/90 [==============================] - 0s 354us/step - loss: 0.5182 - acc: 0.8111 - val_loss: 0.5391 - val_acc: 0.7889\n",
            "Epoch 162/500\n",
            "90/90 [==============================] - 0s 445us/step - loss: 0.5173 - acc: 0.8111 - val_loss: 0.5382 - val_acc: 0.7889\n",
            "Epoch 163/500\n",
            "90/90 [==============================] - 0s 418us/step - loss: 0.5163 - acc: 0.8111 - val_loss: 0.5373 - val_acc: 0.7889\n",
            "Epoch 164/500\n",
            "90/90 [==============================] - 0s 392us/step - loss: 0.5154 - acc: 0.8111 - val_loss: 0.5363 - val_acc: 0.7889\n",
            "Epoch 165/500\n",
            "90/90 [==============================] - 0s 347us/step - loss: 0.5144 - acc: 0.8111 - val_loss: 0.5354 - val_acc: 0.7889\n",
            "Epoch 166/500\n",
            "90/90 [==============================] - 0s 360us/step - loss: 0.5134 - acc: 0.8111 - val_loss: 0.5345 - val_acc: 0.8000\n",
            "Epoch 167/500\n",
            "90/90 [==============================] - 0s 368us/step - loss: 0.5124 - acc: 0.8111 - val_loss: 0.5336 - val_acc: 0.8000\n",
            "Epoch 168/500\n",
            "90/90 [==============================] - 0s 375us/step - loss: 0.5115 - acc: 0.8111 - val_loss: 0.5327 - val_acc: 0.8000\n",
            "Epoch 169/500\n",
            "90/90 [==============================] - 0s 378us/step - loss: 0.5105 - acc: 0.8111 - val_loss: 0.5317 - val_acc: 0.8000\n",
            "Epoch 170/500\n",
            "90/90 [==============================] - 0s 368us/step - loss: 0.5096 - acc: 0.8111 - val_loss: 0.5308 - val_acc: 0.8000\n",
            "Epoch 171/500\n",
            "90/90 [==============================] - 0s 356us/step - loss: 0.5086 - acc: 0.8111 - val_loss: 0.5298 - val_acc: 0.8000\n",
            "Epoch 172/500\n",
            "90/90 [==============================] - 0s 358us/step - loss: 0.5076 - acc: 0.8111 - val_loss: 0.5289 - val_acc: 0.8000\n",
            "Epoch 173/500\n",
            "90/90 [==============================] - 0s 386us/step - loss: 0.5066 - acc: 0.8111 - val_loss: 0.5279 - val_acc: 0.8000\n",
            "Epoch 174/500\n",
            "90/90 [==============================] - 0s 341us/step - loss: 0.5057 - acc: 0.8111 - val_loss: 0.5270 - val_acc: 0.8000\n",
            "Epoch 175/500\n",
            "90/90 [==============================] - 0s 335us/step - loss: 0.5047 - acc: 0.8111 - val_loss: 0.5261 - val_acc: 0.8000\n",
            "Epoch 176/500\n",
            "90/90 [==============================] - 0s 356us/step - loss: 0.5039 - acc: 0.8111 - val_loss: 0.5252 - val_acc: 0.8000\n",
            "Epoch 177/500\n",
            "90/90 [==============================] - 0s 367us/step - loss: 0.5028 - acc: 0.8111 - val_loss: 0.5243 - val_acc: 0.8000\n",
            "Epoch 178/500\n",
            "90/90 [==============================] - 0s 345us/step - loss: 0.5019 - acc: 0.8222 - val_loss: 0.5234 - val_acc: 0.8000\n",
            "Epoch 179/500\n",
            "90/90 [==============================] - 0s 323us/step - loss: 0.5009 - acc: 0.8222 - val_loss: 0.5225 - val_acc: 0.8000\n",
            "Epoch 180/500\n",
            "90/90 [==============================] - 0s 409us/step - loss: 0.5000 - acc: 0.8222 - val_loss: 0.5216 - val_acc: 0.8000\n",
            "Epoch 181/500\n",
            "90/90 [==============================] - 0s 355us/step - loss: 0.4990 - acc: 0.8222 - val_loss: 0.5207 - val_acc: 0.8000\n",
            "Epoch 182/500\n",
            "90/90 [==============================] - 0s 380us/step - loss: 0.4981 - acc: 0.8222 - val_loss: 0.5198 - val_acc: 0.8000\n",
            "Epoch 183/500\n",
            "90/90 [==============================] - 0s 349us/step - loss: 0.4971 - acc: 0.8222 - val_loss: 0.5189 - val_acc: 0.8000\n",
            "Epoch 184/500\n",
            "90/90 [==============================] - 0s 322us/step - loss: 0.4962 - acc: 0.8222 - val_loss: 0.5180 - val_acc: 0.8000\n",
            "Epoch 185/500\n",
            "90/90 [==============================] - 0s 344us/step - loss: 0.4952 - acc: 0.8222 - val_loss: 0.5172 - val_acc: 0.8000\n",
            "Epoch 186/500\n",
            "90/90 [==============================] - 0s 538us/step - loss: 0.4943 - acc: 0.8222 - val_loss: 0.5163 - val_acc: 0.8000\n",
            "Epoch 187/500\n",
            "90/90 [==============================] - 0s 319us/step - loss: 0.4933 - acc: 0.8222 - val_loss: 0.5154 - val_acc: 0.8000\n",
            "Epoch 188/500\n",
            "90/90 [==============================] - 0s 370us/step - loss: 0.4923 - acc: 0.8222 - val_loss: 0.5146 - val_acc: 0.8000\n",
            "Epoch 189/500\n",
            "90/90 [==============================] - 0s 343us/step - loss: 0.4915 - acc: 0.8222 - val_loss: 0.5137 - val_acc: 0.8000\n",
            "Epoch 190/500\n",
            "90/90 [==============================] - 0s 351us/step - loss: 0.4905 - acc: 0.8111 - val_loss: 0.5129 - val_acc: 0.8000\n",
            "Epoch 191/500\n",
            "90/90 [==============================] - 0s 339us/step - loss: 0.4895 - acc: 0.8111 - val_loss: 0.5120 - val_acc: 0.8000\n",
            "Epoch 192/500\n",
            "90/90 [==============================] - 0s 374us/step - loss: 0.4887 - acc: 0.8222 - val_loss: 0.5112 - val_acc: 0.8000\n",
            "Epoch 193/500\n",
            "90/90 [==============================] - 0s 410us/step - loss: 0.4877 - acc: 0.8222 - val_loss: 0.5104 - val_acc: 0.8000\n",
            "Epoch 194/500\n",
            "90/90 [==============================] - 0s 370us/step - loss: 0.4867 - acc: 0.8222 - val_loss: 0.5095 - val_acc: 0.8000\n",
            "Epoch 195/500\n",
            "90/90 [==============================] - 0s 349us/step - loss: 0.4858 - acc: 0.8222 - val_loss: 0.5087 - val_acc: 0.8000\n",
            "Epoch 196/500\n",
            "90/90 [==============================] - 0s 365us/step - loss: 0.4848 - acc: 0.8222 - val_loss: 0.5079 - val_acc: 0.8000\n",
            "Epoch 197/500\n",
            "90/90 [==============================] - 0s 334us/step - loss: 0.4839 - acc: 0.8222 - val_loss: 0.5070 - val_acc: 0.8000\n",
            "Epoch 198/500\n",
            "90/90 [==============================] - 0s 356us/step - loss: 0.4830 - acc: 0.8222 - val_loss: 0.5061 - val_acc: 0.8000\n",
            "Epoch 199/500\n",
            "90/90 [==============================] - 0s 426us/step - loss: 0.4820 - acc: 0.8222 - val_loss: 0.5053 - val_acc: 0.8000\n",
            "Epoch 200/500\n",
            "90/90 [==============================] - 0s 346us/step - loss: 0.4810 - acc: 0.8222 - val_loss: 0.5044 - val_acc: 0.8000\n",
            "Epoch 201/500\n",
            "90/90 [==============================] - 0s 329us/step - loss: 0.4801 - acc: 0.8222 - val_loss: 0.5036 - val_acc: 0.8000\n",
            "Epoch 202/500\n",
            "90/90 [==============================] - 0s 350us/step - loss: 0.4791 - acc: 0.8222 - val_loss: 0.5028 - val_acc: 0.8000\n",
            "Epoch 203/500\n",
            "90/90 [==============================] - 0s 386us/step - loss: 0.4781 - acc: 0.8222 - val_loss: 0.5019 - val_acc: 0.8000\n",
            "Epoch 204/500\n",
            "90/90 [==============================] - 0s 358us/step - loss: 0.4772 - acc: 0.8222 - val_loss: 0.5011 - val_acc: 0.8000\n",
            "Epoch 205/500\n",
            "90/90 [==============================] - 0s 364us/step - loss: 0.4763 - acc: 0.8222 - val_loss: 0.5003 - val_acc: 0.8000\n",
            "Epoch 206/500\n",
            "90/90 [==============================] - 0s 386us/step - loss: 0.4753 - acc: 0.8222 - val_loss: 0.4995 - val_acc: 0.8000\n",
            "Epoch 207/500\n",
            "90/90 [==============================] - 0s 356us/step - loss: 0.4743 - acc: 0.8222 - val_loss: 0.4987 - val_acc: 0.8000\n",
            "Epoch 208/500\n",
            "90/90 [==============================] - 0s 339us/step - loss: 0.4734 - acc: 0.8222 - val_loss: 0.4979 - val_acc: 0.8000\n",
            "Epoch 209/500\n",
            "90/90 [==============================] - 0s 375us/step - loss: 0.4724 - acc: 0.8222 - val_loss: 0.4971 - val_acc: 0.8000\n",
            "Epoch 210/500\n",
            "90/90 [==============================] - 0s 388us/step - loss: 0.4715 - acc: 0.8222 - val_loss: 0.4962 - val_acc: 0.8000\n",
            "Epoch 211/500\n",
            "90/90 [==============================] - 0s 352us/step - loss: 0.4705 - acc: 0.8222 - val_loss: 0.4954 - val_acc: 0.8000\n",
            "Epoch 212/500\n",
            "90/90 [==============================] - 0s 345us/step - loss: 0.4696 - acc: 0.8222 - val_loss: 0.4945 - val_acc: 0.8000\n",
            "Epoch 213/500\n",
            "90/90 [==============================] - 0s 334us/step - loss: 0.4686 - acc: 0.8222 - val_loss: 0.4937 - val_acc: 0.7889\n",
            "Epoch 214/500\n",
            "90/90 [==============================] - 0s 370us/step - loss: 0.4677 - acc: 0.8222 - val_loss: 0.4928 - val_acc: 0.7889\n",
            "Epoch 215/500\n",
            "90/90 [==============================] - 0s 396us/step - loss: 0.4668 - acc: 0.8222 - val_loss: 0.4920 - val_acc: 0.8000\n",
            "Epoch 216/500\n",
            "90/90 [==============================] - 0s 436us/step - loss: 0.4658 - acc: 0.8222 - val_loss: 0.4911 - val_acc: 0.8000\n",
            "Epoch 217/500\n",
            "90/90 [==============================] - 0s 319us/step - loss: 0.4649 - acc: 0.8222 - val_loss: 0.4903 - val_acc: 0.8000\n",
            "Epoch 218/500\n",
            "90/90 [==============================] - 0s 359us/step - loss: 0.4640 - acc: 0.8222 - val_loss: 0.4894 - val_acc: 0.8111\n",
            "Epoch 219/500\n",
            "90/90 [==============================] - 0s 337us/step - loss: 0.4631 - acc: 0.8222 - val_loss: 0.4886 - val_acc: 0.8111\n",
            "Epoch 220/500\n",
            "90/90 [==============================] - 0s 336us/step - loss: 0.4621 - acc: 0.8222 - val_loss: 0.4878 - val_acc: 0.8111\n",
            "Epoch 221/500\n",
            "90/90 [==============================] - 0s 363us/step - loss: 0.4611 - acc: 0.8222 - val_loss: 0.4869 - val_acc: 0.8222\n",
            "Epoch 222/500\n",
            "90/90 [==============================] - 0s 333us/step - loss: 0.4602 - acc: 0.8222 - val_loss: 0.4861 - val_acc: 0.8222\n",
            "Epoch 223/500\n",
            "90/90 [==============================] - 0s 374us/step - loss: 0.4593 - acc: 0.8222 - val_loss: 0.4852 - val_acc: 0.8222\n",
            "Epoch 224/500\n",
            "90/90 [==============================] - 0s 352us/step - loss: 0.4584 - acc: 0.8222 - val_loss: 0.4843 - val_acc: 0.8222\n",
            "Epoch 225/500\n",
            "90/90 [==============================] - 0s 385us/step - loss: 0.4574 - acc: 0.8222 - val_loss: 0.4835 - val_acc: 0.8222\n",
            "Epoch 226/500\n",
            "90/90 [==============================] - 0s 372us/step - loss: 0.4565 - acc: 0.8222 - val_loss: 0.4826 - val_acc: 0.8222\n",
            "Epoch 227/500\n",
            "90/90 [==============================] - 0s 353us/step - loss: 0.4556 - acc: 0.8222 - val_loss: 0.4818 - val_acc: 0.8222\n",
            "Epoch 228/500\n",
            "90/90 [==============================] - 0s 339us/step - loss: 0.4547 - acc: 0.8222 - val_loss: 0.4810 - val_acc: 0.8222\n",
            "Epoch 229/500\n",
            "90/90 [==============================] - 0s 359us/step - loss: 0.4538 - acc: 0.8222 - val_loss: 0.4802 - val_acc: 0.8222\n",
            "Epoch 230/500\n",
            "90/90 [==============================] - 0s 347us/step - loss: 0.4529 - acc: 0.8222 - val_loss: 0.4793 - val_acc: 0.8222\n",
            "Epoch 231/500\n",
            "90/90 [==============================] - 0s 356us/step - loss: 0.4520 - acc: 0.8222 - val_loss: 0.4786 - val_acc: 0.8333\n",
            "Epoch 232/500\n",
            "90/90 [==============================] - 0s 389us/step - loss: 0.4511 - acc: 0.8222 - val_loss: 0.4778 - val_acc: 0.8333\n",
            "Epoch 233/500\n",
            "90/90 [==============================] - 0s 337us/step - loss: 0.4501 - acc: 0.8222 - val_loss: 0.4770 - val_acc: 0.8333\n",
            "Epoch 234/500\n",
            "90/90 [==============================] - 0s 358us/step - loss: 0.4493 - acc: 0.8222 - val_loss: 0.4762 - val_acc: 0.8333\n",
            "Epoch 235/500\n",
            "90/90 [==============================] - 0s 392us/step - loss: 0.4485 - acc: 0.8222 - val_loss: 0.4754 - val_acc: 0.8333\n",
            "Epoch 236/500\n",
            "90/90 [==============================] - 0s 336us/step - loss: 0.4475 - acc: 0.8222 - val_loss: 0.4747 - val_acc: 0.8333\n",
            "Epoch 237/500\n",
            "90/90 [==============================] - 0s 364us/step - loss: 0.4466 - acc: 0.8222 - val_loss: 0.4738 - val_acc: 0.8333\n",
            "Epoch 238/500\n",
            "90/90 [==============================] - 0s 393us/step - loss: 0.4457 - acc: 0.8222 - val_loss: 0.4731 - val_acc: 0.8222\n",
            "Epoch 239/500\n",
            "90/90 [==============================] - 0s 328us/step - loss: 0.4448 - acc: 0.8222 - val_loss: 0.4723 - val_acc: 0.8111\n",
            "Epoch 240/500\n",
            "90/90 [==============================] - 0s 357us/step - loss: 0.4439 - acc: 0.8222 - val_loss: 0.4715 - val_acc: 0.8111\n",
            "Epoch 241/500\n",
            "90/90 [==============================] - 0s 337us/step - loss: 0.4429 - acc: 0.8222 - val_loss: 0.4706 - val_acc: 0.8111\n",
            "Epoch 242/500\n",
            "90/90 [==============================] - 0s 343us/step - loss: 0.4420 - acc: 0.8222 - val_loss: 0.4699 - val_acc: 0.8111\n",
            "Epoch 243/500\n",
            "90/90 [==============================] - 0s 383us/step - loss: 0.4411 - acc: 0.8222 - val_loss: 0.4690 - val_acc: 0.8111\n",
            "Epoch 244/500\n",
            "90/90 [==============================] - 0s 383us/step - loss: 0.4402 - acc: 0.8222 - val_loss: 0.4682 - val_acc: 0.8111\n",
            "Epoch 245/500\n",
            "90/90 [==============================] - 0s 415us/step - loss: 0.4393 - acc: 0.8222 - val_loss: 0.4673 - val_acc: 0.8111\n",
            "Epoch 246/500\n",
            "90/90 [==============================] - 0s 420us/step - loss: 0.4383 - acc: 0.8222 - val_loss: 0.4665 - val_acc: 0.8111\n",
            "Epoch 247/500\n",
            "90/90 [==============================] - 0s 326us/step - loss: 0.4375 - acc: 0.8222 - val_loss: 0.4657 - val_acc: 0.8111\n",
            "Epoch 248/500\n",
            "90/90 [==============================] - 0s 349us/step - loss: 0.4365 - acc: 0.8222 - val_loss: 0.4649 - val_acc: 0.8111\n",
            "Epoch 249/500\n",
            "90/90 [==============================] - 0s 356us/step - loss: 0.4357 - acc: 0.8222 - val_loss: 0.4641 - val_acc: 0.8111\n",
            "Epoch 250/500\n",
            "90/90 [==============================] - 0s 330us/step - loss: 0.4347 - acc: 0.8333 - val_loss: 0.4633 - val_acc: 0.8222\n",
            "Epoch 251/500\n",
            "90/90 [==============================] - 0s 327us/step - loss: 0.4339 - acc: 0.8333 - val_loss: 0.4625 - val_acc: 0.8222\n",
            "Epoch 252/500\n",
            "90/90 [==============================] - 0s 368us/step - loss: 0.4330 - acc: 0.8333 - val_loss: 0.4617 - val_acc: 0.8222\n",
            "Epoch 253/500\n",
            "90/90 [==============================] - 0s 370us/step - loss: 0.4321 - acc: 0.8333 - val_loss: 0.4609 - val_acc: 0.8222\n",
            "Epoch 254/500\n",
            "90/90 [==============================] - 0s 390us/step - loss: 0.4313 - acc: 0.8333 - val_loss: 0.4601 - val_acc: 0.8222\n",
            "Epoch 255/500\n",
            "90/90 [==============================] - 0s 367us/step - loss: 0.4303 - acc: 0.8333 - val_loss: 0.4594 - val_acc: 0.8222\n",
            "Epoch 256/500\n",
            "90/90 [==============================] - 0s 368us/step - loss: 0.4294 - acc: 0.8333 - val_loss: 0.4586 - val_acc: 0.8222\n",
            "Epoch 257/500\n",
            "90/90 [==============================] - 0s 329us/step - loss: 0.4285 - acc: 0.8444 - val_loss: 0.4578 - val_acc: 0.8333\n",
            "Epoch 258/500\n",
            "90/90 [==============================] - 0s 350us/step - loss: 0.4277 - acc: 0.8444 - val_loss: 0.4570 - val_acc: 0.8333\n",
            "Epoch 259/500\n",
            "90/90 [==============================] - 0s 368us/step - loss: 0.4268 - acc: 0.8444 - val_loss: 0.4562 - val_acc: 0.8333\n",
            "Epoch 260/500\n",
            "90/90 [==============================] - 0s 364us/step - loss: 0.4260 - acc: 0.8444 - val_loss: 0.4554 - val_acc: 0.8333\n",
            "Epoch 261/500\n",
            "90/90 [==============================] - 0s 349us/step - loss: 0.4251 - acc: 0.8444 - val_loss: 0.4547 - val_acc: 0.8333\n",
            "Epoch 262/500\n",
            "90/90 [==============================] - 0s 364us/step - loss: 0.4243 - acc: 0.8444 - val_loss: 0.4539 - val_acc: 0.8333\n",
            "Epoch 263/500\n",
            "90/90 [==============================] - 0s 365us/step - loss: 0.4234 - acc: 0.8444 - val_loss: 0.4531 - val_acc: 0.8333\n",
            "Epoch 264/500\n",
            "90/90 [==============================] - 0s 378us/step - loss: 0.4227 - acc: 0.8444 - val_loss: 0.4523 - val_acc: 0.8333\n",
            "Epoch 265/500\n",
            "90/90 [==============================] - 0s 371us/step - loss: 0.4217 - acc: 0.8444 - val_loss: 0.4516 - val_acc: 0.8333\n",
            "Epoch 266/500\n",
            "90/90 [==============================] - 0s 392us/step - loss: 0.4209 - acc: 0.8444 - val_loss: 0.4507 - val_acc: 0.8333\n",
            "Epoch 267/500\n",
            "90/90 [==============================] - 0s 376us/step - loss: 0.4201 - acc: 0.8444 - val_loss: 0.4499 - val_acc: 0.8333\n",
            "Epoch 268/500\n",
            "90/90 [==============================] - 0s 366us/step - loss: 0.4192 - acc: 0.8444 - val_loss: 0.4491 - val_acc: 0.8333\n",
            "Epoch 269/500\n",
            "90/90 [==============================] - 0s 328us/step - loss: 0.4182 - acc: 0.8444 - val_loss: 0.4483 - val_acc: 0.8333\n",
            "Epoch 270/500\n",
            "90/90 [==============================] - 0s 369us/step - loss: 0.4174 - acc: 0.8444 - val_loss: 0.4476 - val_acc: 0.8333\n",
            "Epoch 271/500\n",
            "90/90 [==============================] - 0s 378us/step - loss: 0.4166 - acc: 0.8444 - val_loss: 0.4467 - val_acc: 0.8333\n",
            "Epoch 272/500\n",
            "90/90 [==============================] - 0s 370us/step - loss: 0.4157 - acc: 0.8444 - val_loss: 0.4459 - val_acc: 0.8333\n",
            "Epoch 273/500\n",
            "90/90 [==============================] - 0s 369us/step - loss: 0.4148 - acc: 0.8444 - val_loss: 0.4451 - val_acc: 0.8333\n",
            "Epoch 274/500\n",
            "90/90 [==============================] - 0s 388us/step - loss: 0.4140 - acc: 0.8444 - val_loss: 0.4442 - val_acc: 0.8333\n",
            "Epoch 275/500\n",
            "90/90 [==============================] - 0s 437us/step - loss: 0.4131 - acc: 0.8444 - val_loss: 0.4434 - val_acc: 0.8333\n",
            "Epoch 276/500\n",
            "90/90 [==============================] - 0s 416us/step - loss: 0.4123 - acc: 0.8444 - val_loss: 0.4426 - val_acc: 0.8333\n",
            "Epoch 277/500\n",
            "90/90 [==============================] - 0s 340us/step - loss: 0.4115 - acc: 0.8444 - val_loss: 0.4418 - val_acc: 0.8333\n",
            "Epoch 278/500\n",
            "90/90 [==============================] - 0s 332us/step - loss: 0.4105 - acc: 0.8444 - val_loss: 0.4410 - val_acc: 0.8333\n",
            "Epoch 279/500\n",
            "90/90 [==============================] - 0s 373us/step - loss: 0.4098 - acc: 0.8444 - val_loss: 0.4401 - val_acc: 0.8333\n",
            "Epoch 280/500\n",
            "90/90 [==============================] - 0s 321us/step - loss: 0.4089 - acc: 0.8444 - val_loss: 0.4392 - val_acc: 0.8333\n",
            "Epoch 281/500\n",
            "90/90 [==============================] - 0s 351us/step - loss: 0.4080 - acc: 0.8444 - val_loss: 0.4384 - val_acc: 0.8333\n",
            "Epoch 282/500\n",
            "90/90 [==============================] - 0s 320us/step - loss: 0.4071 - acc: 0.8444 - val_loss: 0.4376 - val_acc: 0.8333\n",
            "Epoch 283/500\n",
            "90/90 [==============================] - 0s 358us/step - loss: 0.4063 - acc: 0.8444 - val_loss: 0.4368 - val_acc: 0.8333\n",
            "Epoch 284/500\n",
            "90/90 [==============================] - 0s 377us/step - loss: 0.4054 - acc: 0.8444 - val_loss: 0.4360 - val_acc: 0.8333\n",
            "Epoch 285/500\n",
            "90/90 [==============================] - 0s 348us/step - loss: 0.4045 - acc: 0.8444 - val_loss: 0.4351 - val_acc: 0.8333\n",
            "Epoch 286/500\n",
            "90/90 [==============================] - 0s 398us/step - loss: 0.4036 - acc: 0.8444 - val_loss: 0.4343 - val_acc: 0.8444\n",
            "Epoch 287/500\n",
            "90/90 [==============================] - 0s 353us/step - loss: 0.4028 - acc: 0.8444 - val_loss: 0.4335 - val_acc: 0.8444\n",
            "Epoch 288/500\n",
            "90/90 [==============================] - 0s 320us/step - loss: 0.4019 - acc: 0.8444 - val_loss: 0.4327 - val_acc: 0.8444\n",
            "Epoch 289/500\n",
            "90/90 [==============================] - 0s 362us/step - loss: 0.4010 - acc: 0.8556 - val_loss: 0.4319 - val_acc: 0.8444\n",
            "Epoch 290/500\n",
            "90/90 [==============================] - 0s 372us/step - loss: 0.4002 - acc: 0.8667 - val_loss: 0.4311 - val_acc: 0.8444\n",
            "Epoch 291/500\n",
            "90/90 [==============================] - 0s 394us/step - loss: 0.3993 - acc: 0.8667 - val_loss: 0.4303 - val_acc: 0.8444\n",
            "Epoch 292/500\n",
            "90/90 [==============================] - 0s 318us/step - loss: 0.3984 - acc: 0.8667 - val_loss: 0.4295 - val_acc: 0.8444\n",
            "Epoch 293/500\n",
            "90/90 [==============================] - 0s 363us/step - loss: 0.3976 - acc: 0.8667 - val_loss: 0.4287 - val_acc: 0.8444\n",
            "Epoch 294/500\n",
            "90/90 [==============================] - 0s 351us/step - loss: 0.3967 - acc: 0.8667 - val_loss: 0.4280 - val_acc: 0.8444\n",
            "Epoch 295/500\n",
            "90/90 [==============================] - 0s 341us/step - loss: 0.3960 - acc: 0.8667 - val_loss: 0.4271 - val_acc: 0.8444\n",
            "Epoch 296/500\n",
            "90/90 [==============================] - 0s 352us/step - loss: 0.3952 - acc: 0.8667 - val_loss: 0.4264 - val_acc: 0.8444\n",
            "Epoch 297/500\n",
            "90/90 [==============================] - 0s 333us/step - loss: 0.3944 - acc: 0.8667 - val_loss: 0.4256 - val_acc: 0.8444\n",
            "Epoch 298/500\n",
            "90/90 [==============================] - 0s 358us/step - loss: 0.3936 - acc: 0.8667 - val_loss: 0.4249 - val_acc: 0.8444\n",
            "Epoch 299/500\n",
            "90/90 [==============================] - 0s 333us/step - loss: 0.3928 - acc: 0.8667 - val_loss: 0.4242 - val_acc: 0.8444\n",
            "Epoch 300/500\n",
            "90/90 [==============================] - 0s 377us/step - loss: 0.3919 - acc: 0.8667 - val_loss: 0.4234 - val_acc: 0.8444\n",
            "Epoch 301/500\n",
            "90/90 [==============================] - 0s 376us/step - loss: 0.3912 - acc: 0.8778 - val_loss: 0.4227 - val_acc: 0.8444\n",
            "Epoch 302/500\n",
            "90/90 [==============================] - 0s 346us/step - loss: 0.3904 - acc: 0.8778 - val_loss: 0.4220 - val_acc: 0.8444\n",
            "Epoch 303/500\n",
            "90/90 [==============================] - 0s 371us/step - loss: 0.3895 - acc: 0.8778 - val_loss: 0.4213 - val_acc: 0.8444\n",
            "Epoch 304/500\n",
            "90/90 [==============================] - 0s 380us/step - loss: 0.3888 - acc: 0.8778 - val_loss: 0.4206 - val_acc: 0.8444\n",
            "Epoch 305/500\n",
            "90/90 [==============================] - 0s 424us/step - loss: 0.3880 - acc: 0.8778 - val_loss: 0.4199 - val_acc: 0.8444\n",
            "Epoch 306/500\n",
            "90/90 [==============================] - 0s 407us/step - loss: 0.3872 - acc: 0.8778 - val_loss: 0.4192 - val_acc: 0.8444\n",
            "Epoch 307/500\n",
            "90/90 [==============================] - 0s 338us/step - loss: 0.3864 - acc: 0.8778 - val_loss: 0.4186 - val_acc: 0.8444\n",
            "Epoch 308/500\n",
            "90/90 [==============================] - 0s 374us/step - loss: 0.3857 - acc: 0.8778 - val_loss: 0.4179 - val_acc: 0.8444\n",
            "Epoch 309/500\n",
            "90/90 [==============================] - 0s 400us/step - loss: 0.3850 - acc: 0.8778 - val_loss: 0.4172 - val_acc: 0.8444\n",
            "Epoch 310/500\n",
            "90/90 [==============================] - 0s 351us/step - loss: 0.3841 - acc: 0.8778 - val_loss: 0.4166 - val_acc: 0.8444\n",
            "Epoch 311/500\n",
            "90/90 [==============================] - 0s 328us/step - loss: 0.3835 - acc: 0.8778 - val_loss: 0.4159 - val_acc: 0.8444\n",
            "Epoch 312/500\n",
            "90/90 [==============================] - 0s 310us/step - loss: 0.3827 - acc: 0.8778 - val_loss: 0.4153 - val_acc: 0.8556\n",
            "Epoch 313/500\n",
            "90/90 [==============================] - 0s 392us/step - loss: 0.3820 - acc: 0.8778 - val_loss: 0.4147 - val_acc: 0.8556\n",
            "Epoch 314/500\n",
            "90/90 [==============================] - 0s 374us/step - loss: 0.3812 - acc: 0.8778 - val_loss: 0.4141 - val_acc: 0.8556\n",
            "Epoch 315/500\n",
            "90/90 [==============================] - 0s 342us/step - loss: 0.3805 - acc: 0.8778 - val_loss: 0.4135 - val_acc: 0.8556\n",
            "Epoch 316/500\n",
            "90/90 [==============================] - 0s 387us/step - loss: 0.3797 - acc: 0.8778 - val_loss: 0.4129 - val_acc: 0.8556\n",
            "Epoch 317/500\n",
            "90/90 [==============================] - 0s 363us/step - loss: 0.3790 - acc: 0.8778 - val_loss: 0.4124 - val_acc: 0.8667\n",
            "Epoch 318/500\n",
            "90/90 [==============================] - 0s 331us/step - loss: 0.3783 - acc: 0.8778 - val_loss: 0.4118 - val_acc: 0.8667\n",
            "Epoch 319/500\n",
            "90/90 [==============================] - 0s 410us/step - loss: 0.3776 - acc: 0.8778 - val_loss: 0.4113 - val_acc: 0.8667\n",
            "Epoch 320/500\n",
            "90/90 [==============================] - 0s 388us/step - loss: 0.3769 - acc: 0.8778 - val_loss: 0.4107 - val_acc: 0.8667\n",
            "Epoch 321/500\n",
            "90/90 [==============================] - 0s 385us/step - loss: 0.3761 - acc: 0.8778 - val_loss: 0.4101 - val_acc: 0.8667\n",
            "Epoch 322/500\n",
            "90/90 [==============================] - 0s 345us/step - loss: 0.3754 - acc: 0.8778 - val_loss: 0.4095 - val_acc: 0.8667\n",
            "Epoch 323/500\n",
            "90/90 [==============================] - 0s 368us/step - loss: 0.3747 - acc: 0.8778 - val_loss: 0.4090 - val_acc: 0.8667\n",
            "Epoch 324/500\n",
            "90/90 [==============================] - 0s 383us/step - loss: 0.3739 - acc: 0.8778 - val_loss: 0.4085 - val_acc: 0.8667\n",
            "Epoch 325/500\n",
            "90/90 [==============================] - 0s 397us/step - loss: 0.3733 - acc: 0.8778 - val_loss: 0.4080 - val_acc: 0.8667\n",
            "Epoch 326/500\n",
            "90/90 [==============================] - 0s 347us/step - loss: 0.3725 - acc: 0.8778 - val_loss: 0.4076 - val_acc: 0.8667\n",
            "Epoch 327/500\n",
            "90/90 [==============================] - 0s 343us/step - loss: 0.3719 - acc: 0.8778 - val_loss: 0.4070 - val_acc: 0.8667\n",
            "Epoch 328/500\n",
            "90/90 [==============================] - 0s 367us/step - loss: 0.3712 - acc: 0.8778 - val_loss: 0.4065 - val_acc: 0.8667\n",
            "Epoch 329/500\n",
            "90/90 [==============================] - 0s 414us/step - loss: 0.3705 - acc: 0.8778 - val_loss: 0.4060 - val_acc: 0.8667\n",
            "Epoch 330/500\n",
            "90/90 [==============================] - 0s 366us/step - loss: 0.3698 - acc: 0.8778 - val_loss: 0.4056 - val_acc: 0.8667\n",
            "Epoch 331/500\n",
            "90/90 [==============================] - 0s 379us/step - loss: 0.3691 - acc: 0.8778 - val_loss: 0.4051 - val_acc: 0.8667\n",
            "Epoch 332/500\n",
            "90/90 [==============================] - 0s 349us/step - loss: 0.3685 - acc: 0.8778 - val_loss: 0.4046 - val_acc: 0.8667\n",
            "Epoch 333/500\n",
            "90/90 [==============================] - 0s 338us/step - loss: 0.3678 - acc: 0.8778 - val_loss: 0.4041 - val_acc: 0.8667\n",
            "Epoch 334/500\n",
            "90/90 [==============================] - 0s 348us/step - loss: 0.3672 - acc: 0.8778 - val_loss: 0.4036 - val_acc: 0.8667\n",
            "Epoch 335/500\n",
            "90/90 [==============================] - 0s 424us/step - loss: 0.3665 - acc: 0.8778 - val_loss: 0.4031 - val_acc: 0.8667\n",
            "Epoch 336/500\n",
            "90/90 [==============================] - 0s 430us/step - loss: 0.3658 - acc: 0.8778 - val_loss: 0.4026 - val_acc: 0.8667\n",
            "Epoch 337/500\n",
            "90/90 [==============================] - 0s 364us/step - loss: 0.3652 - acc: 0.8778 - val_loss: 0.4021 - val_acc: 0.8667\n",
            "Epoch 338/500\n",
            "90/90 [==============================] - 0s 350us/step - loss: 0.3645 - acc: 0.8778 - val_loss: 0.4018 - val_acc: 0.8667\n",
            "Epoch 339/500\n",
            "90/90 [==============================] - 0s 370us/step - loss: 0.3639 - acc: 0.8778 - val_loss: 0.4013 - val_acc: 0.8667\n",
            "Epoch 340/500\n",
            "90/90 [==============================] - 0s 348us/step - loss: 0.3633 - acc: 0.8778 - val_loss: 0.4008 - val_acc: 0.8667\n",
            "Epoch 341/500\n",
            "90/90 [==============================] - 0s 356us/step - loss: 0.3626 - acc: 0.8778 - val_loss: 0.4004 - val_acc: 0.8667\n",
            "Epoch 342/500\n",
            "90/90 [==============================] - 0s 342us/step - loss: 0.3620 - acc: 0.8778 - val_loss: 0.3999 - val_acc: 0.8667\n",
            "Epoch 343/500\n",
            "90/90 [==============================] - 0s 322us/step - loss: 0.3615 - acc: 0.8778 - val_loss: 0.3995 - val_acc: 0.8667\n",
            "Epoch 344/500\n",
            "90/90 [==============================] - 0s 382us/step - loss: 0.3608 - acc: 0.8778 - val_loss: 0.3991 - val_acc: 0.8667\n",
            "Epoch 345/500\n",
            "90/90 [==============================] - 0s 355us/step - loss: 0.3602 - acc: 0.8778 - val_loss: 0.3987 - val_acc: 0.8667\n",
            "Epoch 346/500\n",
            "90/90 [==============================] - 0s 320us/step - loss: 0.3597 - acc: 0.8778 - val_loss: 0.3984 - val_acc: 0.8667\n",
            "Epoch 347/500\n",
            "90/90 [==============================] - 0s 342us/step - loss: 0.3591 - acc: 0.8778 - val_loss: 0.3980 - val_acc: 0.8667\n",
            "Epoch 348/500\n",
            "90/90 [==============================] - 0s 348us/step - loss: 0.3586 - acc: 0.8778 - val_loss: 0.3976 - val_acc: 0.8667\n",
            "Epoch 349/500\n",
            "90/90 [==============================] - 0s 345us/step - loss: 0.3580 - acc: 0.8778 - val_loss: 0.3972 - val_acc: 0.8667\n",
            "Epoch 350/500\n",
            "90/90 [==============================] - 0s 336us/step - loss: 0.3575 - acc: 0.8778 - val_loss: 0.3968 - val_acc: 0.8667\n",
            "Epoch 351/500\n",
            "90/90 [==============================] - 0s 391us/step - loss: 0.3569 - acc: 0.8778 - val_loss: 0.3965 - val_acc: 0.8667\n",
            "Epoch 352/500\n",
            "90/90 [==============================] - 0s 409us/step - loss: 0.3564 - acc: 0.8778 - val_loss: 0.3961 - val_acc: 0.8667\n",
            "Epoch 353/500\n",
            "90/90 [==============================] - 0s 348us/step - loss: 0.3558 - acc: 0.8778 - val_loss: 0.3958 - val_acc: 0.8667\n",
            "Epoch 354/500\n",
            "90/90 [==============================] - 0s 385us/step - loss: 0.3552 - acc: 0.8778 - val_loss: 0.3955 - val_acc: 0.8667\n",
            "Epoch 355/500\n",
            "90/90 [==============================] - 0s 381us/step - loss: 0.3547 - acc: 0.8778 - val_loss: 0.3951 - val_acc: 0.8667\n",
            "Epoch 356/500\n",
            "90/90 [==============================] - 0s 330us/step - loss: 0.3541 - acc: 0.8778 - val_loss: 0.3948 - val_acc: 0.8667\n",
            "Epoch 357/500\n",
            "90/90 [==============================] - 0s 320us/step - loss: 0.3536 - acc: 0.8778 - val_loss: 0.3944 - val_acc: 0.8667\n",
            "Epoch 358/500\n",
            "90/90 [==============================] - 0s 365us/step - loss: 0.3530 - acc: 0.8778 - val_loss: 0.3940 - val_acc: 0.8667\n",
            "Epoch 359/500\n",
            "90/90 [==============================] - 0s 349us/step - loss: 0.3524 - acc: 0.8778 - val_loss: 0.3937 - val_acc: 0.8667\n",
            "Epoch 360/500\n",
            "90/90 [==============================] - 0s 360us/step - loss: 0.3519 - acc: 0.8778 - val_loss: 0.3933 - val_acc: 0.8667\n",
            "Epoch 361/500\n",
            "90/90 [==============================] - 0s 365us/step - loss: 0.3514 - acc: 0.8778 - val_loss: 0.3929 - val_acc: 0.8667\n",
            "Epoch 362/500\n",
            "90/90 [==============================] - 0s 384us/step - loss: 0.3508 - acc: 0.8778 - val_loss: 0.3926 - val_acc: 0.8667\n",
            "Epoch 363/500\n",
            "90/90 [==============================] - 0s 357us/step - loss: 0.3503 - acc: 0.8778 - val_loss: 0.3923 - val_acc: 0.8778\n",
            "Epoch 364/500\n",
            "90/90 [==============================] - 0s 374us/step - loss: 0.3497 - acc: 0.8778 - val_loss: 0.3919 - val_acc: 0.8778\n",
            "Epoch 365/500\n",
            "90/90 [==============================] - 0s 430us/step - loss: 0.3492 - acc: 0.8778 - val_loss: 0.3916 - val_acc: 0.8778\n",
            "Epoch 366/500\n",
            "90/90 [==============================] - 0s 432us/step - loss: 0.3487 - acc: 0.8778 - val_loss: 0.3913 - val_acc: 0.8778\n",
            "Epoch 367/500\n",
            "90/90 [==============================] - 0s 317us/step - loss: 0.3481 - acc: 0.8778 - val_loss: 0.3910 - val_acc: 0.8778\n",
            "Epoch 368/500\n",
            "90/90 [==============================] - 0s 342us/step - loss: 0.3476 - acc: 0.8778 - val_loss: 0.3907 - val_acc: 0.8778\n",
            "Epoch 369/500\n",
            "90/90 [==============================] - 0s 351us/step - loss: 0.3471 - acc: 0.8778 - val_loss: 0.3904 - val_acc: 0.8778\n",
            "Epoch 370/500\n",
            "90/90 [==============================] - 0s 357us/step - loss: 0.3466 - acc: 0.8778 - val_loss: 0.3901 - val_acc: 0.8778\n",
            "Epoch 371/500\n",
            "90/90 [==============================] - 0s 339us/step - loss: 0.3460 - acc: 0.8778 - val_loss: 0.3898 - val_acc: 0.8778\n",
            "Epoch 372/500\n",
            "90/90 [==============================] - 0s 320us/step - loss: 0.3455 - acc: 0.8778 - val_loss: 0.3895 - val_acc: 0.8778\n",
            "Epoch 373/500\n",
            "90/90 [==============================] - 0s 387us/step - loss: 0.3450 - acc: 0.8778 - val_loss: 0.3892 - val_acc: 0.8778\n",
            "Epoch 374/500\n",
            "90/90 [==============================] - 0s 343us/step - loss: 0.3445 - acc: 0.8778 - val_loss: 0.3890 - val_acc: 0.8778\n",
            "Epoch 375/500\n",
            "90/90 [==============================] - 0s 349us/step - loss: 0.3440 - acc: 0.8778 - val_loss: 0.3887 - val_acc: 0.8778\n",
            "Epoch 376/500\n",
            "90/90 [==============================] - 0s 401us/step - loss: 0.3435 - acc: 0.8889 - val_loss: 0.3884 - val_acc: 0.8778\n",
            "Epoch 377/500\n",
            "90/90 [==============================] - 0s 341us/step - loss: 0.3430 - acc: 0.8889 - val_loss: 0.3881 - val_acc: 0.8778\n",
            "Epoch 378/500\n",
            "90/90 [==============================] - 0s 338us/step - loss: 0.3425 - acc: 0.8889 - val_loss: 0.3879 - val_acc: 0.8778\n",
            "Epoch 379/500\n",
            "90/90 [==============================] - 0s 396us/step - loss: 0.3419 - acc: 0.8889 - val_loss: 0.3876 - val_acc: 0.8778\n",
            "Epoch 380/500\n",
            "90/90 [==============================] - 0s 314us/step - loss: 0.3414 - acc: 0.8889 - val_loss: 0.3873 - val_acc: 0.8778\n",
            "Epoch 381/500\n",
            "90/90 [==============================] - 0s 340us/step - loss: 0.3410 - acc: 0.8889 - val_loss: 0.3871 - val_acc: 0.8778\n",
            "Epoch 382/500\n",
            "90/90 [==============================] - 0s 341us/step - loss: 0.3404 - acc: 0.8889 - val_loss: 0.3868 - val_acc: 0.8778\n",
            "Epoch 383/500\n",
            "90/90 [==============================] - 0s 318us/step - loss: 0.3399 - acc: 0.9000 - val_loss: 0.3865 - val_acc: 0.8778\n",
            "Epoch 384/500\n",
            "90/90 [==============================] - 0s 399us/step - loss: 0.3394 - acc: 0.9000 - val_loss: 0.3863 - val_acc: 0.8778\n",
            "Epoch 385/500\n",
            "90/90 [==============================] - 0s 370us/step - loss: 0.3389 - acc: 0.9000 - val_loss: 0.3860 - val_acc: 0.8778\n",
            "Epoch 386/500\n",
            "90/90 [==============================] - 0s 351us/step - loss: 0.3385 - acc: 0.9000 - val_loss: 0.3857 - val_acc: 0.8778\n",
            "Epoch 387/500\n",
            "90/90 [==============================] - 0s 335us/step - loss: 0.3379 - acc: 0.9000 - val_loss: 0.3854 - val_acc: 0.8778\n",
            "Epoch 388/500\n",
            "90/90 [==============================] - 0s 364us/step - loss: 0.3374 - acc: 0.9000 - val_loss: 0.3852 - val_acc: 0.8778\n",
            "Epoch 389/500\n",
            "90/90 [==============================] - 0s 352us/step - loss: 0.3369 - acc: 0.9000 - val_loss: 0.3849 - val_acc: 0.8778\n",
            "Epoch 390/500\n",
            "90/90 [==============================] - 0s 372us/step - loss: 0.3364 - acc: 0.9000 - val_loss: 0.3847 - val_acc: 0.8778\n",
            "Epoch 391/500\n",
            "90/90 [==============================] - 0s 372us/step - loss: 0.3359 - acc: 0.9000 - val_loss: 0.3844 - val_acc: 0.8778\n",
            "Epoch 392/500\n",
            "90/90 [==============================] - 0s 353us/step - loss: 0.3353 - acc: 0.9000 - val_loss: 0.3842 - val_acc: 0.8667\n",
            "Epoch 393/500\n",
            "90/90 [==============================] - 0s 331us/step - loss: 0.3348 - acc: 0.9000 - val_loss: 0.3840 - val_acc: 0.8667\n",
            "Epoch 394/500\n",
            "90/90 [==============================] - 0s 393us/step - loss: 0.3343 - acc: 0.9000 - val_loss: 0.3837 - val_acc: 0.8667\n",
            "Epoch 395/500\n",
            "90/90 [==============================] - 0s 394us/step - loss: 0.3338 - acc: 0.9000 - val_loss: 0.3835 - val_acc: 0.8667\n",
            "Epoch 396/500\n",
            "90/90 [==============================] - 0s 475us/step - loss: 0.3334 - acc: 0.9000 - val_loss: 0.3833 - val_acc: 0.8667\n",
            "Epoch 397/500\n",
            "90/90 [==============================] - 0s 335us/step - loss: 0.3329 - acc: 0.9000 - val_loss: 0.3830 - val_acc: 0.8667\n",
            "Epoch 398/500\n",
            "90/90 [==============================] - 0s 325us/step - loss: 0.3324 - acc: 0.9000 - val_loss: 0.3827 - val_acc: 0.8667\n",
            "Epoch 399/500\n",
            "90/90 [==============================] - 0s 345us/step - loss: 0.3319 - acc: 0.9000 - val_loss: 0.3825 - val_acc: 0.8667\n",
            "Epoch 400/500\n",
            "90/90 [==============================] - 0s 353us/step - loss: 0.3315 - acc: 0.9000 - val_loss: 0.3823 - val_acc: 0.8667\n",
            "Epoch 401/500\n",
            "90/90 [==============================] - 0s 310us/step - loss: 0.3309 - acc: 0.9000 - val_loss: 0.3820 - val_acc: 0.8667\n",
            "Epoch 402/500\n",
            "90/90 [==============================] - 0s 337us/step - loss: 0.3305 - acc: 0.9000 - val_loss: 0.3818 - val_acc: 0.8667\n",
            "Epoch 403/500\n",
            "90/90 [==============================] - 0s 374us/step - loss: 0.3301 - acc: 0.9000 - val_loss: 0.3817 - val_acc: 0.8667\n",
            "Epoch 404/500\n",
            "90/90 [==============================] - 0s 420us/step - loss: 0.3295 - acc: 0.9000 - val_loss: 0.3814 - val_acc: 0.8667\n",
            "Epoch 405/500\n",
            "90/90 [==============================] - 0s 357us/step - loss: 0.3290 - acc: 0.9000 - val_loss: 0.3812 - val_acc: 0.8667\n",
            "Epoch 406/500\n",
            "90/90 [==============================] - 0s 385us/step - loss: 0.3285 - acc: 0.9000 - val_loss: 0.3810 - val_acc: 0.8667\n",
            "Epoch 407/500\n",
            "90/90 [==============================] - 0s 365us/step - loss: 0.3281 - acc: 0.9000 - val_loss: 0.3807 - val_acc: 0.8667\n",
            "Epoch 408/500\n",
            "90/90 [==============================] - 0s 308us/step - loss: 0.3276 - acc: 0.9000 - val_loss: 0.3805 - val_acc: 0.8667\n",
            "Epoch 409/500\n",
            "90/90 [==============================] - 0s 378us/step - loss: 0.3272 - acc: 0.9000 - val_loss: 0.3803 - val_acc: 0.8667\n",
            "Epoch 410/500\n",
            "90/90 [==============================] - 0s 398us/step - loss: 0.3267 - acc: 0.9000 - val_loss: 0.3801 - val_acc: 0.8667\n",
            "Epoch 411/500\n",
            "90/90 [==============================] - 0s 349us/step - loss: 0.3262 - acc: 0.8889 - val_loss: 0.3799 - val_acc: 0.8667\n",
            "Epoch 412/500\n",
            "90/90 [==============================] - 0s 354us/step - loss: 0.3257 - acc: 0.8889 - val_loss: 0.3797 - val_acc: 0.8667\n",
            "Epoch 413/500\n",
            "90/90 [==============================] - 0s 345us/step - loss: 0.3253 - acc: 0.8889 - val_loss: 0.3795 - val_acc: 0.8667\n",
            "Epoch 414/500\n",
            "90/90 [==============================] - 0s 355us/step - loss: 0.3248 - acc: 0.8889 - val_loss: 0.3793 - val_acc: 0.8667\n",
            "Epoch 415/500\n",
            "90/90 [==============================] - 0s 430us/step - loss: 0.3243 - acc: 0.8889 - val_loss: 0.3791 - val_acc: 0.8667\n",
            "Epoch 416/500\n",
            "90/90 [==============================] - 0s 369us/step - loss: 0.3238 - acc: 0.8889 - val_loss: 0.3789 - val_acc: 0.8667\n",
            "Epoch 417/500\n",
            "90/90 [==============================] - 0s 321us/step - loss: 0.3234 - acc: 0.8889 - val_loss: 0.3787 - val_acc: 0.8667\n",
            "Epoch 418/500\n",
            "90/90 [==============================] - 0s 385us/step - loss: 0.3229 - acc: 0.8889 - val_loss: 0.3785 - val_acc: 0.8667\n",
            "Epoch 419/500\n",
            "90/90 [==============================] - 0s 338us/step - loss: 0.3224 - acc: 0.8889 - val_loss: 0.3783 - val_acc: 0.8667\n",
            "Epoch 420/500\n",
            "90/90 [==============================] - 0s 368us/step - loss: 0.3219 - acc: 0.8889 - val_loss: 0.3781 - val_acc: 0.8667\n",
            "Epoch 421/500\n",
            "90/90 [==============================] - 0s 374us/step - loss: 0.3214 - acc: 0.8889 - val_loss: 0.3780 - val_acc: 0.8667\n",
            "Epoch 422/500\n",
            "90/90 [==============================] - 0s 360us/step - loss: 0.3210 - acc: 0.8889 - val_loss: 0.3778 - val_acc: 0.8667\n",
            "Epoch 423/500\n",
            "90/90 [==============================] - 0s 360us/step - loss: 0.3205 - acc: 0.8889 - val_loss: 0.3776 - val_acc: 0.8667\n",
            "Epoch 424/500\n",
            "90/90 [==============================] - 0s 359us/step - loss: 0.3201 - acc: 0.8889 - val_loss: 0.3774 - val_acc: 0.8667\n",
            "Epoch 425/500\n",
            "90/90 [==============================] - 0s 402us/step - loss: 0.3196 - acc: 0.8889 - val_loss: 0.3773 - val_acc: 0.8667\n",
            "Epoch 426/500\n",
            "90/90 [==============================] - 0s 411us/step - loss: 0.3192 - acc: 0.8889 - val_loss: 0.3771 - val_acc: 0.8667\n",
            "Epoch 427/500\n",
            "90/90 [==============================] - 0s 341us/step - loss: 0.3187 - acc: 0.8889 - val_loss: 0.3769 - val_acc: 0.8667\n",
            "Epoch 428/500\n",
            "90/90 [==============================] - 0s 366us/step - loss: 0.3182 - acc: 0.8889 - val_loss: 0.3768 - val_acc: 0.8667\n",
            "Epoch 429/500\n",
            "90/90 [==============================] - 0s 369us/step - loss: 0.3178 - acc: 0.8889 - val_loss: 0.3766 - val_acc: 0.8667\n",
            "Epoch 430/500\n",
            "90/90 [==============================] - 0s 357us/step - loss: 0.3173 - acc: 0.8889 - val_loss: 0.3765 - val_acc: 0.8667\n",
            "Epoch 431/500\n",
            "90/90 [==============================] - 0s 347us/step - loss: 0.3169 - acc: 0.8889 - val_loss: 0.3764 - val_acc: 0.8667\n",
            "Epoch 432/500\n",
            "90/90 [==============================] - 0s 326us/step - loss: 0.3164 - acc: 0.8889 - val_loss: 0.3762 - val_acc: 0.8667\n",
            "Epoch 433/500\n",
            "90/90 [==============================] - 0s 380us/step - loss: 0.3160 - acc: 0.8889 - val_loss: 0.3761 - val_acc: 0.8667\n",
            "Epoch 434/500\n",
            "90/90 [==============================] - 0s 317us/step - loss: 0.3156 - acc: 0.8889 - val_loss: 0.3759 - val_acc: 0.8667\n",
            "Epoch 435/500\n",
            "90/90 [==============================] - 0s 398us/step - loss: 0.3151 - acc: 0.8889 - val_loss: 0.3758 - val_acc: 0.8667\n",
            "Epoch 436/500\n",
            "90/90 [==============================] - 0s 360us/step - loss: 0.3147 - acc: 0.8889 - val_loss: 0.3757 - val_acc: 0.8667\n",
            "Epoch 437/500\n",
            "90/90 [==============================] - 0s 328us/step - loss: 0.3142 - acc: 0.8889 - val_loss: 0.3755 - val_acc: 0.8667\n",
            "Epoch 438/500\n",
            "90/90 [==============================] - 0s 328us/step - loss: 0.3138 - acc: 0.8889 - val_loss: 0.3753 - val_acc: 0.8667\n",
            "Epoch 439/500\n",
            "90/90 [==============================] - 0s 399us/step - loss: 0.3133 - acc: 0.8889 - val_loss: 0.3752 - val_acc: 0.8667\n",
            "Epoch 440/500\n",
            "90/90 [==============================] - 0s 340us/step - loss: 0.3129 - acc: 0.8889 - val_loss: 0.3751 - val_acc: 0.8667\n",
            "Epoch 441/500\n",
            "90/90 [==============================] - 0s 390us/step - loss: 0.3124 - acc: 0.8889 - val_loss: 0.3750 - val_acc: 0.8667\n",
            "Epoch 442/500\n",
            "90/90 [==============================] - 0s 317us/step - loss: 0.3120 - acc: 0.8889 - val_loss: 0.3749 - val_acc: 0.8667\n",
            "Epoch 443/500\n",
            "90/90 [==============================] - 0s 382us/step - loss: 0.3116 - acc: 0.8889 - val_loss: 0.3748 - val_acc: 0.8667\n",
            "Epoch 444/500\n",
            "90/90 [==============================] - 0s 334us/step - loss: 0.3111 - acc: 0.8889 - val_loss: 0.3747 - val_acc: 0.8667\n",
            "Epoch 445/500\n",
            "90/90 [==============================] - 0s 364us/step - loss: 0.3107 - acc: 0.8889 - val_loss: 0.3746 - val_acc: 0.8667\n",
            "Epoch 446/500\n",
            "90/90 [==============================] - 0s 343us/step - loss: 0.3102 - acc: 0.8889 - val_loss: 0.3745 - val_acc: 0.8667\n",
            "Epoch 447/500\n",
            "90/90 [==============================] - 0s 335us/step - loss: 0.3098 - acc: 0.8889 - val_loss: 0.3744 - val_acc: 0.8556\n",
            "Epoch 448/500\n",
            "90/90 [==============================] - 0s 368us/step - loss: 0.3093 - acc: 0.8889 - val_loss: 0.3742 - val_acc: 0.8556\n",
            "Epoch 449/500\n",
            "90/90 [==============================] - 0s 364us/step - loss: 0.3089 - acc: 0.8889 - val_loss: 0.3741 - val_acc: 0.8556\n",
            "Epoch 450/500\n",
            "90/90 [==============================] - 0s 325us/step - loss: 0.3085 - acc: 0.8889 - val_loss: 0.3740 - val_acc: 0.8556\n",
            "Epoch 451/500\n",
            "90/90 [==============================] - 0s 359us/step - loss: 0.3080 - acc: 0.8889 - val_loss: 0.3739 - val_acc: 0.8556\n",
            "Epoch 452/500\n",
            "90/90 [==============================] - 0s 357us/step - loss: 0.3076 - acc: 0.8889 - val_loss: 0.3738 - val_acc: 0.8556\n",
            "Epoch 453/500\n",
            "90/90 [==============================] - 0s 368us/step - loss: 0.3071 - acc: 0.8889 - val_loss: 0.3737 - val_acc: 0.8556\n",
            "Epoch 454/500\n",
            "90/90 [==============================] - 0s 357us/step - loss: 0.3067 - acc: 0.8889 - val_loss: 0.3736 - val_acc: 0.8556\n",
            "Epoch 455/500\n",
            "90/90 [==============================] - 0s 476us/step - loss: 0.3063 - acc: 0.8889 - val_loss: 0.3735 - val_acc: 0.8556\n",
            "Epoch 456/500\n",
            "90/90 [==============================] - 0s 383us/step - loss: 0.3058 - acc: 0.8889 - val_loss: 0.3733 - val_acc: 0.8556\n",
            "Epoch 457/500\n",
            "90/90 [==============================] - 0s 333us/step - loss: 0.3054 - acc: 0.8889 - val_loss: 0.3732 - val_acc: 0.8556\n",
            "Epoch 458/500\n",
            "90/90 [==============================] - 0s 349us/step - loss: 0.3050 - acc: 0.8889 - val_loss: 0.3731 - val_acc: 0.8556\n",
            "Epoch 459/500\n",
            "90/90 [==============================] - 0s 343us/step - loss: 0.3045 - acc: 0.8889 - val_loss: 0.3731 - val_acc: 0.8556\n",
            "Epoch 460/500\n",
            "90/90 [==============================] - 0s 353us/step - loss: 0.3041 - acc: 0.8778 - val_loss: 0.3730 - val_acc: 0.8556\n",
            "Epoch 461/500\n",
            "90/90 [==============================] - 0s 355us/step - loss: 0.3037 - acc: 0.8778 - val_loss: 0.3729 - val_acc: 0.8556\n",
            "Epoch 462/500\n",
            "90/90 [==============================] - 0s 344us/step - loss: 0.3032 - acc: 0.8778 - val_loss: 0.3728 - val_acc: 0.8556\n",
            "Epoch 463/500\n",
            "90/90 [==============================] - 0s 390us/step - loss: 0.3028 - acc: 0.8889 - val_loss: 0.3728 - val_acc: 0.8556\n",
            "Epoch 464/500\n",
            "90/90 [==============================] - 0s 390us/step - loss: 0.3024 - acc: 0.8889 - val_loss: 0.3727 - val_acc: 0.8556\n",
            "Epoch 465/500\n",
            "90/90 [==============================] - 0s 330us/step - loss: 0.3020 - acc: 0.8889 - val_loss: 0.3726 - val_acc: 0.8556\n",
            "Epoch 466/500\n",
            "90/90 [==============================] - 0s 352us/step - loss: 0.3016 - acc: 0.8889 - val_loss: 0.3725 - val_acc: 0.8556\n",
            "Epoch 467/500\n",
            "90/90 [==============================] - 0s 410us/step - loss: 0.3012 - acc: 0.8889 - val_loss: 0.3724 - val_acc: 0.8556\n",
            "Epoch 468/500\n",
            "90/90 [==============================] - 0s 368us/step - loss: 0.3008 - acc: 0.8889 - val_loss: 0.3724 - val_acc: 0.8556\n",
            "Epoch 469/500\n",
            "90/90 [==============================] - 0s 373us/step - loss: 0.3004 - acc: 0.8889 - val_loss: 0.3723 - val_acc: 0.8556\n",
            "Epoch 470/500\n",
            "90/90 [==============================] - 0s 369us/step - loss: 0.3000 - acc: 0.8889 - val_loss: 0.3723 - val_acc: 0.8556\n",
            "Epoch 471/500\n",
            "90/90 [==============================] - 0s 343us/step - loss: 0.2996 - acc: 0.8889 - val_loss: 0.3722 - val_acc: 0.8556\n",
            "Epoch 472/500\n",
            "90/90 [==============================] - 0s 358us/step - loss: 0.2992 - acc: 0.8889 - val_loss: 0.3721 - val_acc: 0.8556\n",
            "Epoch 473/500\n",
            "90/90 [==============================] - 0s 366us/step - loss: 0.2987 - acc: 0.8889 - val_loss: 0.3721 - val_acc: 0.8556\n",
            "Epoch 474/500\n",
            "90/90 [==============================] - 0s 375us/step - loss: 0.2984 - acc: 0.8889 - val_loss: 0.3720 - val_acc: 0.8556\n",
            "Epoch 475/500\n",
            "90/90 [==============================] - 0s 356us/step - loss: 0.2980 - acc: 0.8889 - val_loss: 0.3720 - val_acc: 0.8556\n",
            "Epoch 476/500\n",
            "90/90 [==============================] - 0s 366us/step - loss: 0.2976 - acc: 0.8889 - val_loss: 0.3720 - val_acc: 0.8556\n",
            "Epoch 477/500\n",
            "90/90 [==============================] - 0s 317us/step - loss: 0.2972 - acc: 0.8889 - val_loss: 0.3720 - val_acc: 0.8556\n",
            "Epoch 478/500\n",
            "90/90 [==============================] - 0s 381us/step - loss: 0.2968 - acc: 0.8889 - val_loss: 0.3720 - val_acc: 0.8556\n",
            "Epoch 479/500\n",
            "90/90 [==============================] - 0s 326us/step - loss: 0.2964 - acc: 0.8889 - val_loss: 0.3720 - val_acc: 0.8556\n",
            "Epoch 480/500\n",
            "90/90 [==============================] - 0s 358us/step - loss: 0.2961 - acc: 0.8889 - val_loss: 0.3720 - val_acc: 0.8556\n",
            "Epoch 481/500\n",
            "90/90 [==============================] - 0s 375us/step - loss: 0.2957 - acc: 0.8889 - val_loss: 0.3720 - val_acc: 0.8556\n",
            "Epoch 482/500\n",
            "90/90 [==============================] - 0s 405us/step - loss: 0.2952 - acc: 0.8889 - val_loss: 0.3720 - val_acc: 0.8556\n",
            "Epoch 483/500\n",
            "90/90 [==============================] - 0s 363us/step - loss: 0.2949 - acc: 0.8889 - val_loss: 0.3720 - val_acc: 0.8556\n",
            "Epoch 484/500\n",
            "90/90 [==============================] - 0s 359us/step - loss: 0.2945 - acc: 0.8889 - val_loss: 0.3720 - val_acc: 0.8556\n",
            "Epoch 485/500\n",
            "90/90 [==============================] - 0s 470us/step - loss: 0.2941 - acc: 0.8889 - val_loss: 0.3720 - val_acc: 0.8556\n",
            "Epoch 486/500\n",
            "90/90 [==============================] - 0s 403us/step - loss: 0.2937 - acc: 0.8889 - val_loss: 0.3720 - val_acc: 0.8556\n",
            "Epoch 487/500\n",
            "90/90 [==============================] - 0s 392us/step - loss: 0.2934 - acc: 0.8889 - val_loss: 0.3720 - val_acc: 0.8556\n",
            "Epoch 488/500\n",
            "90/90 [==============================] - 0s 355us/step - loss: 0.2930 - acc: 0.8889 - val_loss: 0.3720 - val_acc: 0.8556\n",
            "Epoch 489/500\n",
            "90/90 [==============================] - 0s 411us/step - loss: 0.2926 - acc: 0.8889 - val_loss: 0.3720 - val_acc: 0.8556\n",
            "Epoch 490/500\n",
            "90/90 [==============================] - 0s 422us/step - loss: 0.2922 - acc: 0.8889 - val_loss: 0.3720 - val_acc: 0.8556\n",
            "Epoch 491/500\n",
            "90/90 [==============================] - 0s 380us/step - loss: 0.2919 - acc: 0.8889 - val_loss: 0.3720 - val_acc: 0.8556\n",
            "Epoch 492/500\n",
            "90/90 [==============================] - 0s 353us/step - loss: 0.2915 - acc: 0.8889 - val_loss: 0.3720 - val_acc: 0.8556\n",
            "Epoch 493/500\n",
            "90/90 [==============================] - 0s 339us/step - loss: 0.2911 - acc: 0.8889 - val_loss: 0.3720 - val_acc: 0.8556\n",
            "Epoch 494/500\n",
            "90/90 [==============================] - 0s 340us/step - loss: 0.2908 - acc: 0.8889 - val_loss: 0.3720 - val_acc: 0.8556\n",
            "Epoch 495/500\n",
            "90/90 [==============================] - 0s 359us/step - loss: 0.2904 - acc: 0.8889 - val_loss: 0.3720 - val_acc: 0.8556\n",
            "Epoch 496/500\n",
            "90/90 [==============================] - 0s 389us/step - loss: 0.2900 - acc: 0.8889 - val_loss: 0.3720 - val_acc: 0.8556\n",
            "Epoch 497/500\n",
            "90/90 [==============================] - 0s 367us/step - loss: 0.2896 - acc: 0.8889 - val_loss: 0.3720 - val_acc: 0.8556\n",
            "Epoch 498/500\n",
            "90/90 [==============================] - 0s 334us/step - loss: 0.2892 - acc: 0.8889 - val_loss: 0.3720 - val_acc: 0.8556\n",
            "Epoch 499/500\n",
            "90/90 [==============================] - 0s 362us/step - loss: 0.2889 - acc: 0.8889 - val_loss: 0.3720 - val_acc: 0.8556\n",
            "Epoch 500/500\n",
            "90/90 [==============================] - 0s 346us/step - loss: 0.2885 - acc: 0.8889 - val_loss: 0.3720 - val_acc: 0.8556\n",
            "90/90 [==============================] - 0s 155us/step\n",
            "\n",
            "Test Accuracy: 85.56%\n",
            "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAFnCAYAAAC/5tBZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFnCAYAAACPasF4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nt4iIiItReIuIiLgYhbeIiIiL+X/QGU5sMB48ogAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "7nUN1oO78oQk",
        "colab_type": "code",
        "outputId": "ab6a345d-55da-493f-bbc6-30e622bfe452",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "fin_test = pd.read_csv('../test_values_normalized.csv', index_col=0)\n",
        "xfin_test = fin_test.drop('patient_id',1) #Drops/deletes patient_id column\n",
        "\n",
        "fin_proba = model.predict(xfin_test,verbose=1)\n",
        "bin_proba = [prob[1] for prob in fin_proba]\n",
        "submission = pd.DataFrame({'patient_id': fin_test.patient_id.values, \n",
        "                           'heart_disease_present': bin_proba})\n",
        "submission = submission[['patient_id', 'heart_disease_present']]\n",
        "submission.to_csv(\"my_submission.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "90/90 [==============================] - 3s 34ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}